{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from mappings import classToAnsible, ansibleToClass # need to get the mapping to ansible from json\n",
    "import yaml\n",
    "import pprint\n",
    "from isConfigurableMap import isConfigurableMap # need to get the \n",
    "from collections import Counter\n",
    "from collections import deque\n",
    "from defaultClassAttrValues import defaults\n",
    "from exceptionDict import exceptions\n",
    "from requiredParamsAliasesMap import requiredParamsAliases, reverse_alias_map\n",
    "from paramAliasMap import paramAliasMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file\n",
    "\n",
    "with open('tn-nils-4.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is mostly chatGPT, will need to rewrite it and figure out how to do this without it\n",
    "\n",
    "names = []\n",
    "\n",
    "def prune_dict(data):\n",
    "    def contains_name_key(d):\n",
    "        # Check if 'name' key is in the current dictionary\n",
    "        if 'name' in d:\n",
    "            return True\n",
    "        # Check nested dictionaries\n",
    "        for key, value in d.items():\n",
    "            if isinstance(value, dict) and contains_name_key(value):\n",
    "                return True\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, dict) and contains_name_key(item):\n",
    "                        return True\n",
    "        return False\n",
    "\n",
    "    def prune(d):\n",
    "        keys_to_delete = []\n",
    "        for key, value in d.items():\n",
    "            if isinstance(value, dict):\n",
    "                if not contains_name_key(value):\n",
    "                    keys_to_delete.append(key)\n",
    "                else:\n",
    "                    prune(value)\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, dict):\n",
    "                        prune(item)\n",
    "\n",
    "        for key in keys_to_delete:\n",
    "            del d[key]\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        prune(data)\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            if isinstance(item, dict):\n",
    "                prune(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maybe only modules appear in the playbooks, not classes (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_isConfigurable_to_ansible(data):\n",
    "    for key, value in data.items():\n",
    "        map_json_to_ansible(data, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aci-meta-5.3-2c.json', 'r') as file:\n",
    "    meta = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "PATH_TO_MODULE_DIR = \"/Users/lpaggen/Documents/research_project/ansible-aci/modules\"\n",
    "\n",
    "def get_file_paths(dir):\n",
    "    py_files = []\n",
    "    for file in os.listdir(dir):\n",
    "        file_path = os.path.join(dir, file)\n",
    "        if file.endswith(\".py\"):\n",
    "            py_files.append(file_path)\n",
    "    return py_files\n",
    "\n",
    "# code is bad at the moment, will address if needed, for the time being it runs well enough\n",
    "\n",
    "def extract_parameter_aliases(dir):\n",
    "    count = 0\n",
    "\n",
    "    py_files = get_file_paths(dir)\n",
    "    out = {}\n",
    "\n",
    "    # regex \n",
    "    # finds the block of code in source code after \"argument_spec.update()\"\n",
    "    pattern = re.compile(r'argument_spec\\.update\\(\\s*(.*?)^\\s*\\)', re.DOTALL | re.MULTILINE)\n",
    "    pattern2 = re.compile(r\"([a-zA-Z_]+)\\s*=\\s*dict\", re.MULTILINE)\n",
    "    pattern3 = re.compile(r\"([a-zA-Z_]+)\\s*=\\s*dict\\s*\\((.*?)\\)\", re.DOTALL)\n",
    "    \n",
    "    # finds the aliases of the params according to what is found in match 3\n",
    "    pattern4 = re.compile(r'(?<=aliases=\\[)([^\\]]*)', re.DOTALL | re.MULTILINE)\n",
    "    \n",
    "    # finds the block of code in source after \"class_config=dict()\"\n",
    "    pattern5 = re.compile(r'class_config\\s*=\\s*dict\\s*\\(\\s*([^)]+)', re.DOTALL)\n",
    "    \n",
    "    # finds the kw in the pattern5\n",
    "    pattern6 = re.compile(r\"([^=,\\s]+)=([^'\\n,]*)\")\n",
    "\n",
    "    for file_path in py_files:\n",
    "        with open(file_path, 'r') as file:\n",
    "            file_content = file.read()\n",
    "\n",
    "        matches = pattern.findall(file_content)\n",
    "        match5 = pattern5.findall(file_content)\n",
    "\n",
    "        entry_dict = {}  # nested dict\n",
    "\n",
    "        for entries_str in matches:\n",
    "            match2 = pattern2.findall(entries_str) # list of the parameters\n",
    "            match3 = pattern3.findall(entries_str)\n",
    "\n",
    "            if match3:\n",
    "                for idx, i in enumerate(match3): # get idx to find correspondance in match2\n",
    "                    match4 = pattern4.findall(str(i)) # need string otherwise error sometimes\n",
    "                    if match4:\n",
    "                        for j in match4:\n",
    "                            entry_dict[match2[idx]] = [i.replace(\"\\\"\", \"\").replace(\" \", \"\") for i in j.split(\",\")] # clean string\n",
    "                    else:\n",
    "                        entry_dict[match2[idx]] = None\n",
    "\n",
    "            # now this looks for the second set of aliases (source code seems to be weird)\n",
    "            # it should overwrite the \"None\" values if any\n",
    "            # if match5:\n",
    "            #     for idx, i in enumerate(match5):\n",
    "            #         temp = i.split(\",\")\n",
    "            #         # print(file_path.split(\"/\")[-1][:-3])\n",
    "            #         for j in temp:\n",
    "            #             match6 = pattern6.search(str(j))\n",
    "            #             if match6:\n",
    "            #                 # print(match6.group(2), match6.group(1))\n",
    "            #                 try:\n",
    "            #                     if entry_dict[match6.group(2)] == None:\n",
    "            #                         entry_dict[match6.group(2)] = [match6.group(1)] # \",\".join([i for i in match6.group(1)])\n",
    "            #                     elif match6.group(2) != None and type(match6.group(2)) != str: # error somewhere\n",
    "            #                         entry_dict[match6.group(2)].append(match6.group(1))\n",
    "            #                 except(KeyError):\n",
    "            #                     entry_dict[match6.group(2)] = [match6.group(1)]\n",
    "\n",
    "                print(\"\\n\")\n",
    "\n",
    "        out[file_path.split(\"/\")[-1][:-3]] = entry_dict\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this parser just gets the rnFormat of each class\n",
    "\n",
    "def getClassRnFormat(data):\n",
    "    out = {}\n",
    "\n",
    "    def process_data(data, parent_key = None):\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "\n",
    "                if key == \"rnFormat\":\n",
    "                    try:\n",
    "                        entry_key = classToAnsible[parent_key]\n",
    "                    except(KeyError):\n",
    "                        entry_key = parent_key\n",
    "\n",
    "                    out[entry_key] = value if len(value) > 0 else None\n",
    "\n",
    "                if isinstance(value, (dict, list)):\n",
    "                    process_data(value, key)\n",
    "\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                if isinstance(item, (dict, list)):\n",
    "                    process_data(item, parent_key)\n",
    "\n",
    "    process_data(data)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = getClassRnFormat(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary has been saved to classRnFormat.py\n"
     ]
    }
   ],
   "source": [
    "# save to file\n",
    "with open(\"classRnFormat.py\", 'w') as file:\n",
    "    file.write(\"rnFormat = \")\n",
    "    pprint.pprint(a, stream=file)\n",
    "\n",
    "print(f\"Dictionary has been saved to classRnFormat.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# need way to decide which mapping, according to the parent in the json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exception_list=['spanDestGrp',\n",
    "                'spanSrcGrp',\n",
    "                'spanSrc',\n",
    "                'mgmtMaintP',\n",
    "                'spanRsSrcToPathEp',\n",
    "                'fvSubnet',\n",
    "                'fvRsPathAtt',\n",
    "                'vzBrCP',\n",
    "                'dhcpRelayP',\n",
    "                'infraRsVlanNs',\n",
    "                'fvRsSecInherited',\n",
    "                'l1PhysIf',\n",
    "                'l2extInstP',\n",
    "                'mgmtOoB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'spanDestGrp': 3,\n",
       "         'spanSrcGrp': 3,\n",
       "         'spanSrc': 3,\n",
       "         'mgmtMaintP': 3,\n",
       "         'spanRsSrcToPathEp': 2,\n",
       "         'fvSubnet': 2,\n",
       "         'fvRsPathAtt': 2,\n",
       "         'vzBrCP': 2,\n",
       "         'dhcpRelayP': 2,\n",
       "         'infraRsVlanNs': 2,\n",
       "         'fvRsSecInherited': 2,\n",
       "         'l1PhysIf': 2,\n",
       "         'l2extInstP': 2,\n",
       "         'mgmtOoB': 2,\n",
       "         'leakInternalSubnet': 1,\n",
       "         'leakRoutes': 1,\n",
       "         'leakTo': 1,\n",
       "         'aaaRbacClassPriv': 1,\n",
       "         'aaaDomain': 1,\n",
       "         'aaaRole': 1,\n",
       "         'aaaSshAuth': 1,\n",
       "         'aaaUser': 1,\n",
       "         'aaaUserCert': 1,\n",
       "         'aaaUserDomain': 1,\n",
       "         'aaaUserRole': 1,\n",
       "         'infraHPortS, infraPortBlk': 1,\n",
       "         'infraHPortS, infraRsAccBaseGrp, infraPortBlk': 1,\n",
       "         'spanFilterGrp': 1,\n",
       "         'spanFilterEntry': 1,\n",
       "         'infraHPortS, infraSubPortBlk': 1,\n",
       "         'infraAttEntityP, infraProvAcc': 1,\n",
       "         'infraRsDomP': 1,\n",
       "         'infraRsFuncToEpg': 1,\n",
       "         'fvAp': 1,\n",
       "         'fvBD': 1,\n",
       "         'dhcpLbl': 1,\n",
       "         'fvRsBDToOut': 1,\n",
       "         'bgpRRAsnP': 1,\n",
       "         'bgpRRNodeP': 1,\n",
       "         'cloudApp': 1,\n",
       "         'cloudAwsProvider': 1,\n",
       "         'cloudBgpAsP': 1,\n",
       "         'cloudCidr': 1,\n",
       "         'cloudCtxProfile': 1,\n",
       "         'cloudEPg': 1,\n",
       "         'cloudEPSelector': 1,\n",
       "         'cloudExtEPg': 1,\n",
       "         'cloudExtEPSelector': 1,\n",
       "         'cloudProvP': 1,\n",
       "         'cloudRegion': 1,\n",
       "         'cloudSubnet': 1,\n",
       "         'cloudcloudRouterP': 1,\n",
       "         'cloudZone': 1,\n",
       "         'configExportP': 1,\n",
       "         'configImportP': 1,\n",
       "         'configSnapshot, configExportP': 1,\n",
       "         'vzCPIf': 1,\n",
       "         'vzSubj': 1,\n",
       "         'vzRsSubjFiltAtt': 1,\n",
       "         'vzRsSubjGraphAtt': 1,\n",
       "         'dnsDomain': 1,\n",
       "         'dnsProfile': 1,\n",
       "         'dnsProv': 1,\n",
       "         'physDomP, vmmDomP, l2extDomP, l3extDomP, fcDomP': 1,\n",
       "         'fvnsVlanInstP, fvnsVxlanInstP, fvnsVsanInstP': 1,\n",
       "         'fvnsEncapBlk, fvnsVsanEncapBlk': 1,\n",
       "         'fvAEPg': 1,\n",
       "         'monEPGPol': 1,\n",
       "         'fvRsCons, fvRsProv': 1,\n",
       "         'fvRsConsIf': 1,\n",
       "         'fvRsDomAtt': 1,\n",
       "         'fvESg': 1,\n",
       "         'fvfvEPgSelector': 1,\n",
       "         'fvEPSelector': 1,\n",
       "         'fvTagSelector': 1,\n",
       "         'fabricLeafP': 1,\n",
       "         'fabricLeafS, fabricRsLeNodePGrp': 1,\n",
       "         'fabricNodeIdentP': 1,\n",
       "         'fabricPodPGrp': 1,\n",
       "         'fabricSchedulerP': 1,\n",
       "         'spanRsSrcToNode': 1,\n",
       "         'fabricSpineP': 1,\n",
       "         'fabricSpineS, fabricRsSpNodePGrp': 1,\n",
       "         'fabricNodeBlk': 1,\n",
       "         'fabricSwitchPolGrp': 1,\n",
       "         'fileRemotePath': 1,\n",
       "         'vzFilter': 1,\n",
       "         'vzEntry': 1,\n",
       "         'firmwareGroup': 1,\n",
       "         'firmwareGroupNode': 1,\n",
       "         'firmwarePolicy': 1,\n",
       "         'firmwareSource': 1,\n",
       "         'igmpIfPol': 1,\n",
       "         'l1PhysIfBlacklist': 1,\n",
       "         'cdpIfPol': 1,\n",
       "         'fcIfPol': 1,\n",
       "         'l2IfPol': 1,\n",
       "         'infraBrkoutPortGrp': 1,\n",
       "         'infraAccBndlGrp, infraAccPortGrp': 1,\n",
       "         'infraAccPortP': 1,\n",
       "         'infraFexBndlGrp': 1,\n",
       "         'fabricHIfPol': 1,\n",
       "         'lldpIfPol': 1,\n",
       "         'mcpIfPol': 1,\n",
       "         'ospfIfPol': 1,\n",
       "         'lacpLagPol': 1,\n",
       "         'l2PortSecurityPol': 1,\n",
       "         'stpIfPol': 1,\n",
       "         'infraRsAccPortP': 1,\n",
       "         'l2extOut': 1,\n",
       "         'l2extRsPathL2OutAtt': 1,\n",
       "         'l2extLIfP': 1,\n",
       "         'l2extLNodeP': 1,\n",
       "         'l3extOut': 1,\n",
       "         'bgpPeerP': 1,\n",
       "         'l3extInstPinstP': 1,\n",
       "         'l3extInstP': 1,\n",
       "         'l3extSubnetextsubnet': 1,\n",
       "         'l3extRsPathL3OutAtt': 1,\n",
       "         'l3extIp': 1,\n",
       "         'l3extLIfP': 1,\n",
       "         'ospfIfP': 1,\n",
       "         'l3extMember': 1,\n",
       "         'l3extRsNodeL3OutAtt': 1,\n",
       "         'l3extLNodePlnodep': 1,\n",
       "         'l3extRouteTagPol': 1,\n",
       "         'l3extipRouteP': 1,\n",
       "         'ipNexthopP': 1,\n",
       "         'datetimePol': 1,\n",
       "         'datetimeNtpProvider': 1,\n",
       "         'mgmtRsRestOutAtt': 1,\n",
       "         'snmpClientP': 1,\n",
       "         'snmpClientGrpP': 1,\n",
       "         'snmpCommunityP': 1,\n",
       "         'snmpPol': 1,\n",
       "         'snmpUserP': 1,\n",
       "         'infraLeafS, infraNodeBlk, infraRsAccNodePGrep': 1,\n",
       "         'infraNodeP': 1,\n",
       "         'fabricExplicitGEp, fabricNodePEp': 1,\n",
       "         'syslogGroup, syslogConsole, syslogFile and syslogProf': 1,\n",
       "         'syslogRemoteDest': 1,\n",
       "         'syslogSrc': 1,\n",
       "         'topSystem': 1,\n",
       "         'tagAliasDelInst': 1,\n",
       "         'fvTenant': 1,\n",
       "         'rtctrlAttrP': 1,\n",
       "         'fvEpRetPol': 1,\n",
       "         'spanSpanLbl': 1,\n",
       "         'fvnsVlanInstP': 1,\n",
       "         'fvnsEncapBlk': 1,\n",
       "         'vmmCtrlrP': 1,\n",
       "         'vmmUsrAccP': 1,\n",
       "         'vmmUplinkP': 1,\n",
       "         'vmmUplinkPCont': 1,\n",
       "         'vmmDomP': 1,\n",
       "         'fvCtx': 1,\n",
       "         'fvleakInternalSubnet': 1,\n",
       "         'vzRsAnyToProv, vzRsAnyToCons, vzRsAnyToConsIf': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(ansibleToClass.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defaultClassAttrValues import defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverseAliases = reverse_alias_map(requiredParamsAliases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO \n",
    "\n",
    "## add a list which can hold all children dictionaries somehow, NEEDED to rebuild the final yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_yml(data, out_dir=None):\n",
    "    save_path = \"ansible_reconstructed.yml\" if out_dir is None else os.path.join(out_dir, \"ansible_reconstructed.yml\")\n",
    "\n",
    "    # here define default arguments (to delete)\n",
    "    default_args = ['', \"\", \"::\", \":all:\"]\n",
    "\n",
    "    # invisible_arguments\n",
    "    invisible_args = [\"annotation\", \"dn\"] # adjust as needed\n",
    "\n",
    "    # define exception list\n",
    "    exception_list = ['aci_access_span_src_group',\n",
    "                        'aci_bd',\n",
    "                        'aci_bd_dhcp_label',\n",
    "                        'aci_bd_subnet',\n",
    "                        'aci_domain_to_vlan_pool',\n",
    "                        'aci_epg_subnet',\n",
    "                        'aci_fabric_span_src_group',\n",
    "                        'aci_tenant_span_src_group',\n",
    "                        'aci_tenant_span_src_group_src']\n",
    "    \n",
    "    # here define duplicates list - handle dupes in values of class mappings\n",
    "    # key (class) : value (dict) -> key (parent class) : value (correct mapping)\n",
    "\n",
    "    duplicate_list = ['spanDestGrp', 'spanSrcGrp', 'spanSrc',\n",
    "                      'mgmtMaintP', 'spanRsSrcToPathEp', 'fvSubnet',\n",
    "                      'fvRsPathAtt', 'vzBrCP', 'dhcpRelayP',\n",
    "                      'infraRsVlanNs', 'fvRsSecInherited', 'l1PhysIf',\n",
    "                      'l2extInstP', 'mgmtOoB']\n",
    "\n",
    "    # TO DO\n",
    "    # finish this mapping\n",
    "    duplicate_map = {\n",
    "        # 'spanDestGrp': None,\n",
    "        # 'spanSrcGrp': None,\n",
    "        # 'spanSrc': None,\n",
    "        # 'mgmtMaintP': None,\n",
    "        # 'spanRsSrcToPathEp': None,\n",
    "        'fvSubnet': {'aci_epg': 'aci_epg_subnet',\n",
    "                     'aci_bd': 'aci_bd_subnet'},\n",
    "        # 'fvRsPathAtt': None,\n",
    "        'vzBrCP': \"aci_contract\",\n",
    "        # 'dhcpRelayP': None,\n",
    "        # 'infraRsVlanNs': None,\n",
    "        # 'fvRsSecInherited': None,\n",
    "        # 'l1PhysIf': None,\n",
    "        # 'l2extInstP': None,\n",
    "        # 'mgmtOoB': None\n",
    "        }\n",
    "    \n",
    "    def map_json_to_ansible(json_data, key, map):\n",
    "        try:\n",
    "            new_key = map[key]\n",
    "            json_data[new_key] = json_data.pop(key) # replace with ansible term\n",
    "        except(KeyError): # no match found, skip\n",
    "            pass\n",
    "\n",
    "    def remove_isNotConfigurable(key, delete_key_list):\n",
    "        try:\n",
    "            if isConfigurableMap[key] == False:\n",
    "                delete_key_list.append(key)\n",
    "            else:\n",
    "                pass\n",
    "        except(KeyError):\n",
    "            pass\n",
    "\n",
    "    # helper method to navigate the exception dictionary\n",
    "    def map_if_duplicate(child, parent = None):\n",
    "        out = None\n",
    "        try:\n",
    "            out = duplicate_map[child][parent]\n",
    "        except(KeyError):\n",
    "            out = duplicate_map[child] # means there is no exception with the parent\n",
    "        return out\n",
    "\n",
    "    # simple method to check if a key in in the exception list\n",
    "    # need to run this stuff before mapping anything - mapping is ambiguous\n",
    "    def isduplicate(key):\n",
    "        return key in duplicate_list\n",
    "\n",
    "    def isdefault(parent_key, key, value, map):\n",
    "        try:\n",
    "            return value == map[parent_key][key] # means attribute has a default value\n",
    "        except(KeyError):\n",
    "            return False\n",
    "        \n",
    "    def isexception(key): # checks if key in exceptions\n",
    "        try:\n",
    "            return classToAnsible[key] in exception_list\n",
    "        except(KeyError):\n",
    "            return False\n",
    "\n",
    "    def isfullydefault(val, parent_key, default_map, second_default_map):\n",
    "        try:\n",
    "            # convert defaults to sets \n",
    "            default_values_set = set(default_map[parent_key].values())\n",
    "            second_default_values_set = set(second_default_map)\n",
    "            \n",
    "            # combine default args and default mapping\n",
    "            combined_default_values_set = default_values_set.union(second_default_values_set)\n",
    "            \n",
    "            # to set \n",
    "            val_set = set(val)\n",
    "            \n",
    "            # check if subset\n",
    "            return val_set.issubset(combined_default_values_set)\n",
    "        except KeyError: # anything which is not \"fv\" is here atm\n",
    "            return True # change based on desired behavior\n",
    "        \n",
    "    def save_to_yaml(save_path, data):\n",
    "        # save_path = os.path.join(save_path, \"ansible_reconstructed.yml\")\n",
    "        with open(save_path, 'w') as file:\n",
    "            yaml.dump(data, file, default_flow_style=False)\n",
    "        print(f\"YAML file has been saved to {save_path}\")\n",
    "\n",
    "    # process data recursively\n",
    "    # we need to track many parent-child keys, including some of sublists etc\n",
    "    def process(data, parent_key:str = None, children_parent_key:str = None, attribute_parent_key:str = None, default_map:dict = defaults, dn:dict = {}, subclasses = []) -> dict:\n",
    "        \"\"\"\n",
    "\n",
    "        Handles mapping of \n",
    "        - classes to ansible\n",
    "        - class parameters to ansible\n",
    "\n",
    "        Gets rid of the \"attributes\" field found in the JSON config \n",
    "\n",
    "        Gets rid of any fields with default values\n",
    "\n",
    "        Handles duplicates in mappings\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        changes = []\n",
    "\n",
    "        yml_tasks = [] # we will also need a list of the nested dictionaries for yml correct format\n",
    "\n",
    "        if isinstance(data, dict):\n",
    "            keys_to_delete = [] # maintain this list outside any loop, prevents \"changed size\" errors\n",
    "\n",
    "            for key, value in data.items():\n",
    "\n",
    "                # handle dn - name of parent in child, grandchild etc etc\n",
    "                if isinstance(value, dict) and \"children\" in value.keys():\n",
    "                    try:\n",
    "                        dn_key = reverseAliases[classToAnsible[key]][\"name\"][:-1]\n",
    "                        dn_val = data[key]['attributes'][\"name\"]\n",
    "                        dn[dn_key] = dn_val\n",
    "                    except(KeyError):\n",
    "                        pass\n",
    "\n",
    "                # all CLASSES are handled, exceptions..\n",
    "                # TO DO -> handle exceptions like \"changes\"\n",
    "                # also not quite sure everything we are looking for is exclusively under \"children\" ...\n",
    "                if key == \"children\":\n",
    "                    children_parent_key = parent_key\n",
    "\n",
    "                    # children ALWAYS contains a nested list of nested dictionaries\n",
    "                    for item in value:\n",
    "                        for chld_key, chld_value in item.items():\n",
    "\n",
    "                            # the last element of each tuple in \"changes\" is an integer\n",
    "                            # this is ONLY TO IDENTIFY WHICH TYPE OF CHANGE IS NEEDED\n",
    "\n",
    "                            # handle duplicate mappings FIRST\n",
    "                            if isduplicate(chld_key):\n",
    "                                changes.append((children_parent_key, chld_key, chld_value, 0))\n",
    "\n",
    "                # all PARAMETERS are processed and mapped if needed\n",
    "                elif key == \"attributes\": # these are all the parameters of the classes\n",
    "                    attribute_parent_key = parent_key\n",
    "\n",
    "                    # check if all attributes are default; if so, skip processing entirely\n",
    "                    # empty dictionaries function will take care of it\n",
    "                    if not isfullydefault(value.values(), parent_key, defaults, default_args):\n",
    "\n",
    "                        if isexception(parent_key):\n",
    "\n",
    "                            # TYPE 1 EXCEPTIONS -> ADD PARAMS WHICH ARE FOUND IN SUBCLASSES (handled same as type2 actually)\n",
    "                            try:\n",
    "                                for param, path in exceptions[classToAnsible[parent_key]].items():\n",
    "                                    for item in data['children']: # it seems \"children\" is almost always found here\n",
    "                                        if path[0] in item.keys():\n",
    "                                            changes.append((parent_key, param, item[path[0]][path[1]][path[2]], 2))\n",
    "\n",
    "                                            # append the class we will \"throw away\"\n",
    "                                            subclasses.append(path[0])\n",
    "                                            print(subclasses)\n",
    "\n",
    "                                            #######\n",
    "                                            # path[0] is the exception class we need to get rid of, maybe through the changes system\n",
    "                                            #######\n",
    "\n",
    "                            except(KeyError) as e:\n",
    "                                print(f\"KeyError encountered: {e}\")\n",
    "                                pass\n",
    "\n",
    "                        # TYPE 2 -> fix the dn attributes missing from children classes\n",
    "                        if len(dn) > 0:\n",
    "                            # assuming dn can only be a stack 2 long\n",
    "                            if len(dn) > 2:\n",
    "                                dn_list = list(dn.items())\n",
    "                                dn_list.pop(1)\n",
    "                                dn = dict(dn_list)\n",
    "                            for dn_key, dn_val in dn.items():\n",
    "                                changes.append((attribute_parent_key, dn_key, dn_val, 2))\n",
    "\n",
    "                        # TYPE 2 CHANGES -> ATTRIBUTES FIELD REMOVAL, REMOVAL OF DEFAULTS\n",
    "                        # append all non default params to \"changes\" - mapping and deletion is done here\n",
    "                        for attr_key, attr_value in value.items(): # here empty values are also handled, eg if default then don't change\n",
    "                            if attr_key not in invisible_args and attr_value not in default_args and not isdefault(attribute_parent_key, attr_key, attr_value, default_map):\n",
    "\n",
    "                                # proper to fv_subnet once again?\n",
    "                                # new exception found with \"ip\" -> creates a mask\n",
    "                                if attr_key == \"ip\":\n",
    "                                    attr_key = \"gateway\"\n",
    "                                    changes.append((attribute_parent_key, 'mask', int(attr_value[-2:]), 2))\n",
    "\n",
    "                                attr_value = attr_value if attr_key != \"gateway\" else attr_value[:-3]\n",
    "\n",
    "                                changes.append((attribute_parent_key, attr_key, attr_value, 2)) # appends a tuple\n",
    "\n",
    "                        # atm hardcoding \"present\" into yml, change later if needed\n",
    "                        changes.append((attribute_parent_key, 'state', 'present', 2))\n",
    "\n",
    "                    keys_to_delete.append(\"attributes\") # can append key too\n",
    "\n",
    "                # any exception will be caught here and will crash the entire program\n",
    "                # therefore we want no exceptions\n",
    "                if isinstance(value, (dict, list)):\n",
    "                    try:\n",
    "                        process(value, key, attribute_parent_key, dn)\n",
    "                    except (KeyError) as e:\n",
    "                        print(data['mldSnoopPol'])\n",
    "                        print(f\"Error processing key {key}: {e}\")\n",
    "                        pass\n",
    "\n",
    "                if isinstance(value, dict) and not value:\n",
    "                    keys_to_delete.append(key)\n",
    "\n",
    "                remove_isNotConfigurable(key, keys_to_delete) # change to boolean check? \n",
    "\n",
    "            # any modification to the dict can only be made outside the loops\n",
    "            for key in keys_to_delete:\n",
    "                try:\n",
    "                    del data[key]\n",
    "                except(KeyError):\n",
    "                    pass\n",
    "\n",
    "            # use the mapping function\n",
    "            for key in list(data.keys()):\n",
    "                if key not in duplicate_list: # mapping done elsewhere for dupes\n",
    "                    map_json_to_ansible(data, key, classToAnsible)\n",
    "\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                if isinstance(item, (dict, list)):\n",
    "                    process(item, parent_key, attribute_parent_key, dn)\n",
    "\n",
    "        # accessing keys in \"data\" instead of passing through a parent_key works\n",
    "        # BECAUSE OF RECURSION, we are handling nested dictionaries as \"data\" everytime !!!!!!\n",
    "        for change in changes:\n",
    "            parent_key, child_key, child_value, change_type = change  # \"change\" is a 3x tuple\n",
    "            if change_type == 2: # ATTRIBUTES parent key\n",
    "                try:\n",
    "                    new_key = reverseAliases[classToAnsible[parent_key]][child_key]\n",
    "                    # at the moment no use for the required tag, can change later on if we need it somehow\n",
    "                    if new_key[-1] == \"*\":\n",
    "                        new_key = new_key[:-1]\n",
    "\n",
    "                    data[new_key] = child_value\n",
    "                    if child_key in data and new_key != child_key: # UNSURE if this is necessary anymore ..\n",
    "                        del data[child_key]\n",
    "                except KeyError:\n",
    "                    data[child_key] = child_value\n",
    "\n",
    "            # DOUBLE CHECK logic here, otherwise seems to work as expected\n",
    "            # also can get rid of the whole \"CHILDREN\" key and move all upwards when we need it, only issue is how does this translate in yml\n",
    "            # FOR NOW keep \"children\" key as it helps with ordering everything correctly\n",
    "            elif change_type == 0: # CHILDREN parent key, DUPLICATE CASES\n",
    "                try:\n",
    "                    new_key = map_if_duplicate(child_key, classToAnsible[parent_key])\n",
    "                    data['children'][0][new_key] = child_value\n",
    "                    if child_key in data['children'][0]: # is this always the case? 0 idx? double check logic\n",
    "                        del data['children'][0][child_key]\n",
    "                except(KeyError):\n",
    "                    pass\n",
    "\n",
    "        return data\n",
    "\n",
    "    # this function gets rid of empty structures in the output, think of {} for example\n",
    "    # code is from GPT\n",
    "    def remove_empty_dicts(data):\n",
    "        if isinstance(data, dict):\n",
    "            return {k: remove_empty_dicts(v) for k, v in data.items() if remove_empty_dicts(v)} # see return of function for why this works\n",
    "        elif isinstance(data, list):\n",
    "            for idx, item in enumerate(data):\n",
    "                if isinstance(item, dict) and len(item) == 0:\n",
    "                    data.pop(idx)\n",
    "                else:\n",
    "                    data[idx] = remove_empty_dicts(item)\n",
    "            return data\n",
    "        else:\n",
    "            return data # this basically evaluates to false when the structure is None\n",
    "\n",
    "    def rebuild_yml(data, credentials_file = None):\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                print(key)\n",
    "\n",
    "                if isinstance(value, dict):\n",
    "                    rebuild_yml(value)\n",
    "                elif isinstance(value, list):\n",
    "                    for item in value:\n",
    "                        rebuild_yml(item)\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                rebuild_yml(item)\n",
    "\n",
    "    # handle reconstruction of yml with recursion\n",
    "    def rebuild_yml(data, credentials_file = None, yml_list = [], parent_key = None):\n",
    "\n",
    "        entry_dict = {}\n",
    "\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                nested_dictionary = {}\n",
    "\n",
    "                # here restructuring is handled\n",
    "                if parent_key == \"children\" or parent_key == None:\n",
    "                    entry_dict[\"name\"] = \"THIS IS NOT SET YET\"\n",
    "                    for subkey, subvalue in data[key].items():\n",
    "                        if subkey != \"children\":\n",
    "                            # print(key, subkey, subvalue)\n",
    "                            nested_dictionary[subkey] = subvalue\n",
    "                    entry_dict[\"cisco.aci.\" + key] = nested_dictionary\n",
    "                    entry_dict[\"delegate_to\"] = \"localhost\"\n",
    "\n",
    "                    yml_list.append(entry_dict)\n",
    "\n",
    "                if isinstance(value, dict):\n",
    "                    rebuild_yml(value, parent_key = key)\n",
    "\n",
    "                elif isinstance(value, list):\n",
    "                    for item in value:\n",
    "                        rebuild_yml(item, parent_key = key)\n",
    "\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                rebuild_yml(item, parent_key = key)\n",
    "\n",
    "        return yml_list\n",
    "\n",
    "    # process the initial data\n",
    "    a = process(data)\n",
    "\n",
    "    # delete the empty dictionaries\n",
    "    b = remove_empty_dicts(a)\n",
    "\n",
    "    save_to_yaml(\"ansible_reconstructed.yml\", data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tn-nils-5.json\", 'r') as file:\n",
    "    y = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fvRsBdToEpRet']\n",
      "['fvRsBdToEpRet', 'fvRsBdToEpRet']\n",
      "['fvRsBdToEpRet', 'fvRsBdToEpRet', 'fvRsIgmpsn']\n",
      "['fvRsBdToEpRet', 'fvRsBdToEpRet', 'fvRsIgmpsn', 'fvRsBDToNdP']\n",
      "['fvRsBdToEpRet', 'fvRsBdToEpRet', 'fvRsIgmpsn', 'fvRsBDToNdP', 'fvRsMldsn']\n",
      "['fvRsBdToEpRet', 'fvRsBdToEpRet', 'fvRsIgmpsn', 'fvRsBDToNdP', 'fvRsMldsn', 'fvRsCtx']\n",
      "KeyError encountered: 'children'\n",
      "YAML file has been saved to ansible_reconstructed.yml\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 61.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = reconstruct_yml(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aci_tenant': {'children': [{'fvRsTenantMonPol': {'tenant': 'nils',\n",
       "     'name': 'bobaf',\n",
       "     'modTs': '2024-07-05T00:55:16.386+00:00',\n",
       "     'monPolDn': 'uni/tn-common/monepg-default',\n",
       "     'rn': 'rsTenantMonPol',\n",
       "     'state': 'present',\n",
       "     'stateQual': 'default-target',\n",
       "     'tDn': 'uni/tn-common/monepg-default',\n",
       "     'tRn': 'monepg-default',\n",
       "     'uid': '0'}},\n",
       "   {'fvEpTags': {'tenant': 'nils',\n",
       "     'name': 'bobaf',\n",
       "     'modTs': '2024-07-05T00:55:16.386+00:00',\n",
       "     'monPolDn': 'uni/tn-common/monepg-default',\n",
       "     'rn': 'eptags',\n",
       "     'uid': '0',\n",
       "     'state': 'present'}},\n",
       "   {'aci_tenant_ep_retention_policy': {'tenant': 'nils',\n",
       "     'epr_policy': 'mangaboul',\n",
       "     'modTs': '2024-07-16T02:20:56.723+00:00',\n",
       "     'rn': 'epRPol-mangaboul',\n",
       "     'uid': '15374',\n",
       "     'state': 'present'}},\n",
       "   {'aci_vrf': {'children': [{'fvRsVrfValidationPol': {'tenant': 'nils',\n",
       "        'epr_policy': 'mangaboul',\n",
       "        'vrf': 'bob',\n",
       "        'modTs': '2024-07-05T00:55:19.652+00:00',\n",
       "        'monPolDn': 'uni/tn-common/monepg-default',\n",
       "        'rn': 'rsvrfValidationPol',\n",
       "        'state': 'present',\n",
       "        'stateQual': 'default-target',\n",
       "        'tDn': 'uni/tn-common/vrfvalidationpol-default',\n",
       "        'tRn': 'vrfvalidationpol-default',\n",
       "        'uid': '0'}},\n",
       "      {'fvRsOspfCtxPol': {'tenant': 'nils',\n",
       "        'epr_policy': 'mangaboul',\n",
       "        'vrf': 'bob',\n",
       "        'modTs': '2024-07-05T00:55:19.652+00:00',\n",
       "        'monPolDn': 'uni/tn-common/monepg-default',\n",
       "        'rn': 'rsospfCtxPol',\n",
       "        'state': 'present',\n",
       "        'stateQual': 'default-target',\n",
       "        'tDn': 'uni/tn-common/ospfCtxP-default',\n",
       "        'tRn': 'ospfCtxP-default',\n",
       "        'uid': '0'}},\n",
       "      {'fvRsCtxToEpRet': {'tenant': 'nils',\n",
       "        'epr_policy': 'mangaboul',\n",
       "        'vrf': 'bob',\n",
       "        'modTs': '2024-07-05T00:55:19.652+00:00',\n",
       "        'monPolDn': 'uni/tn-common/monepg-default',\n",
       "        'rn': 'rsctxToEpRet',\n",
       "        'state': 'present',\n",
       "        'stateQual': 'default-target',\n",
       "        'tDn': 'uni/tn-common/epRPol-default',\n",
       "        'tRn': 'epRPol-default',\n",
       "        'uid': '0'}},\n",
       "      {'fvRsCtxToExtRouteTagPol': {'tenant': 'nils',\n",
       "        'epr_policy': 'mangaboul',\n",
       "        'vrf': 'bob',\n",
       "        'modTs': '2024-07-05T00:55:19.652+00:00',\n",
       "        'monPolDn': 'uni/tn-common/monepg-default',\n",
       "        'rn': 'rsctxToExtRouteTagPol',\n",
       "        'state': 'present',\n",
       "        'stateQual': 'default-target',\n",
       "        'tDn': 'uni/tn-common/rttag-default',\n",
       "        'tRn': 'rttag-default',\n",
       "        'uid': '0'}},\n",
       "      {'fvRsBgpCtxPol': {'tenant': 'nils',\n",
       "        'epr_policy': 'mangaboul',\n",
       "        'vrf': 'bob',\n",
       "        'modTs': '2024-07-05T00:55:19.652+00:00',\n",
       "        'monPolDn': 'uni/tn-common/monepg-default',\n",
       "        'rn': 'rsbgpCtxPol',\n",
       "        'state': 'present',\n",
       "        'stateQual': 'default-target',\n",
       "        'tDn': 'uni/tn-common/bgpCtxP-default',\n",
       "        'tRn': 'bgpCtxP-default',\n",
       "        'uid': '0'}}],\n",
       "     'tenant': 'nils',\n",
       "     'epr_policy': 'mangaboul',\n",
       "     'vrf': 'bob',\n",
       "     'description': 'marcel',\n",
       "     'modTs': '2024-07-05T00:55:19.682+00:00',\n",
       "     'monPolDn': 'uni/tn-common/monepg-default',\n",
       "     'pcEnfDirUpdated': 'yes',\n",
       "     'pcTag': '32770',\n",
       "     'rn': 'ctx-bob',\n",
       "     'scope': '2326529',\n",
       "     'seg': '2326529',\n",
       "     'uid': '15374',\n",
       "     'state': 'present'}},\n",
       "   {'aci_bd': {'children': [{'aci_bd_subnet': {'tenant': 'nils',\n",
       "        'epr_policy': 'mangaboul',\n",
       "        'vrf': 'bob',\n",
       "        'bd': 'tintin',\n",
       "        'mask': 24,\n",
       "        'gateway': '10.10.10.1',\n",
       "        'modTs': '2024-07-06T04:21:54.805+00:00',\n",
       "        'monPolDn': 'uni/tn-common/monepg-default',\n",
       "        'rn': 'subnet-[10.10.10.1/24]',\n",
       "        'scope': 'public,shared',\n",
       "        'uid': '15374',\n",
       "        'state': 'present'}},\n",
       "      {'fvSubnet': {'tenant': 'nils',\n",
       "        'epr_policy': 'mangaboul',\n",
       "        'vrf': 'bob',\n",
       "        'bd': 'tintin',\n",
       "        'mask': 24,\n",
       "        'gateway': '10.10.10.1',\n",
       "        'modTs': '2024-07-06T04:21:54.805+00:00',\n",
       "        'monPolDn': 'uni/tn-common/monepg-default',\n",
       "        'rn': 'subnet-[10.10.10.1/24]',\n",
       "        'scope': 'public,shared',\n",
       "        'uid': '15374',\n",
       "        'state': 'present'}},\n",
       "      {'fvRsMldsn': {'tenant': 'nils',\n",
       "        'epr_policy': 'mangaboul',\n",
       "        'vrf': 'bob',\n",
       "        'bd': 'tintin',\n",
       "        'modTs': '2024-07-16T02:21:26.858+00:00',\n",
       "        'monPolDn': 'uni/tn-common/monepg-default',\n",
       "        'rn': 'rsmldsn',\n",
       "        'state': 'present',\n",
       "        'tDn': 'uni/tn-nils/mldsnoopPol-bilbocquet',\n",
       "        'tRn': 'mldsnoopPol-bilbocquet',\n",
       "        'tnMldSnoopPolName': 'bilbocquet',\n",
       "        'uid': '0'}},\n",
       "      {'fvRsIgmpsn': {'tenant': 'nils',\n",
       "        'epr_policy': 'mangaboul',\n",
       "        'vrf': 'bob',\n",
       "        'bd': 'tintin',\n",
       "        'modTs': '2024-07-16T02:21:26.858+00:00',\n",
       "        'monPolDn': 'uni/tn-common/monepg-default',\n",
       "        'rn': 'rsigmpsn',\n",
       "        'state': 'present',\n",
       "        'tDn': 'uni/tn-nils/snPol-chiendetalus',\n",
       "        'tRn': 'snPol-chiendetalus',\n",
       "        'tnIgmpSnoopPolName': 'chiendetalus',\n",
       "        'uid': '0'}},\n",
       "      {'fvRsCtx': {'tenant': 'nils',\n",
       "        'epr_policy': 'mangaboul',\n",
       "        'vrf': 'bob',\n",
       "        'bd': 'tintin',\n",
       "        'modTs': '2024-07-06T04:21:51.608+00:00',\n",
       "        'monPolDn': 'uni/tn-common/monepg-default',\n",
       "        'rn': 'rsctx',\n",
       "        'state': 'present',\n",
       "        'tDn': 'uni/tn-nils/ctx-bob',\n",
       "        'tRn': 'ctx-bob',\n",
       "        'tnFvCtxName': 'bob',\n",
       "        'uid': '0'}},\n",
       "      {'fvRsBdToEpRet': {'tenant': 'nils',\n",
       "        'epr_policy': 'mangaboul',\n",
       "        'vrf': 'bob',\n",
       "        'bd': 'tintin',\n",
       "        'modTs': '2024-07-16T02:21:26.858+00:00',\n",
       "        'monPolDn': 'uni/tn-common/monepg-default',\n",
       "        'rn': 'rsbdToEpRet',\n",
       "        'state': 'present',\n",
       "        'tDn': 'uni/tn-nils/epRPol-mangaboul',\n",
       "        'tRn': 'epRPol-mangaboul',\n",
       "        'tnFvEpRetPolName': 'mangaboul',\n",
       "        'uid': '0'}},\n",
       "      {'fvRsBDToNdP': {'tenant': 'nils',\n",
       "        'epr_policy': 'mangaboul',\n",
       "        'vrf': 'bob',\n",
       "        'bd': 'tintin',\n",
       "        'modTs': '2024-07-06T04:21:51.684+00:00',\n",
       "        'monPolDn': 'uni/tn-common/monepg-default',\n",
       "        'rn': 'rsBDToNdP',\n",
       "        'state': 'present',\n",
       "        'stateQual': 'default-target',\n",
       "        'tDn': 'uni/tn-common/ndifpol-default',\n",
       "        'tRn': 'ndifpol-default',\n",
       "        'uid': '0'}}],\n",
       "     'endpoint_retention_action': 'resolve',\n",
       "     'endpoint_retention_policy': 'mangaboul',\n",
       "     'igmp_snoop_policy': 'chiendetalus',\n",
       "     'mld_snoop_policy': 'bilbocquet',\n",
       "     'vrf': 'bob',\n",
       "     'tenant': 'nils',\n",
       "     'epr_policy': 'mangaboul',\n",
       "     'bd': 'tintin',\n",
       "     'bcastP': '225.1.156.64',\n",
       "     'enable_rogue_except_mac': 'no',\n",
       "     'mac_address': '00:22:BD:F8:19:FF',\n",
       "     'modTs': '2024-07-16T02:21:26.858+00:00',\n",
       "     'monPolDn': 'uni/tn-common/monepg-default',\n",
       "     'pcTag': '49153',\n",
       "     'rn': 'BD-tintin',\n",
       "     'scope': '2326529',\n",
       "     'seg': '16154554',\n",
       "     'uid': '15374',\n",
       "     'state': 'present'}}],\n",
       "  'tenant': 'nils',\n",
       "  'modTs': '2024-07-05T00:55:16.386+00:00',\n",
       "  'monPolDn': 'uni/tn-common/monepg-default',\n",
       "  'uid': '15374',\n",
       "  'state': 'present'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file has been saved to ansible_reconstructed.yml\n"
     ]
    }
   ],
   "source": [
    "# handle reconstruction of yml with recursion\n",
    "\n",
    "# TO DO -> ADD REMVOVAL OF \"fvRs\" CLASSES, too hard to handle above due to recursive issues\n",
    "\n",
    "def rebuild_yml(data, credentials_file = None, yml_list = [], parent_key = None, grandparent_key = None):\n",
    "\n",
    "    entry_dict = {}\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "\n",
    "            nested_dictionary = {}\n",
    "\n",
    "            # here restructuring is handled\n",
    "            if parent_key == \"children\" or parent_key == None:\n",
    "\n",
    "                # bad trick to get rid of all non-aci modules\n",
    "                if key[:3] == \"aci\":\n",
    "                    pass\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "                # set name to something generic\n",
    "                key_name = key.split(\"_\")[1] if len(key.split(\"_\")) == 2 else key.split(\"_\")[2]\n",
    "                if parent_key != None:\n",
    "                    grandparent_key_name = grandparent_key.split(\"_\")[1] if len(grandparent_key.split(\"_\")) == 2 else grandparent_key.split(\"_\")[2:]\n",
    "                    sentence = f\"add a {key_name.upper()} to the {grandparent_key_name.upper()}\"\n",
    "                else:\n",
    "                    sentence = f\"create {key_name} on ACI using {key} module\"\n",
    "\n",
    "                entry_dict[\"name\"] = sentence\n",
    "                for subkey, subvalue in data[key].items():\n",
    "                    if subkey != \"children\":\n",
    "                        # print(key, subkey, subvalue)\n",
    "                        nested_dictionary[subkey] = subvalue\n",
    "                entry_dict[\"cisco.aci.\" + key] = nested_dictionary\n",
    "                entry_dict[\"delegate_to\"] = \"localhost\"\n",
    "\n",
    "                yml_list.append(entry_dict)\n",
    "\n",
    "            if isinstance(value, dict):\n",
    "                rebuild_yml(value, parent_key = key, grandparent_key = parent_key)\n",
    "\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    rebuild_yml(item, parent_key = key, grandparent_key = parent_key)\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            rebuild_yml(item, parent_key = key, grandparent_key = parent_key)\n",
    "\n",
    "    return yml_list\n",
    "\n",
    "a = rebuild_yml(test)\n",
    "\n",
    "with open(\"ansible_reconstructed.yml\", 'w') as file:\n",
    "    yaml.dump(a, file, default_flow_style = False, sort_keys = False)\n",
    "print(f\"YAML file has been saved to ansible_reconstructed.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'create tenant on ACI using aci_tenant module',\n",
       "  'cisco.aci.aci_tenant': {'tenant': 'nils',\n",
       "   'modTs': '2024-07-05T00:55:16.386+00:00',\n",
       "   'monPolDn': 'uni/tn-common/monepg-default',\n",
       "   'uid': '15374',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a EP to the TENANT',\n",
       "  'cisco.aci.aci_tenant_ep_retention_policy': {'tenant': 'nils',\n",
       "   'epr_policy': 'mangaboul',\n",
       "   'modTs': '2024-07-16T02:20:56.723+00:00',\n",
       "   'rn': 'epRPol-mangaboul',\n",
       "   'uid': '15374',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a VRF to the TENANT',\n",
       "  'cisco.aci.aci_vrf': {'tenant': 'nils',\n",
       "   'epr_policy': 'mangaboul',\n",
       "   'vrf': 'bob',\n",
       "   'description': 'marcel',\n",
       "   'modTs': '2024-07-05T00:55:19.682+00:00',\n",
       "   'monPolDn': 'uni/tn-common/monepg-default',\n",
       "   'pcEnfDirUpdated': 'yes',\n",
       "   'pcTag': '32770',\n",
       "   'rn': 'ctx-bob',\n",
       "   'scope': '2326529',\n",
       "   'seg': '2326529',\n",
       "   'uid': '15374',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a BD to the TENANT',\n",
       "  'cisco.aci.aci_bd': {'endpoint_retention_action': 'resolve',\n",
       "   'endpoint_retention_policy': 'mangaboul',\n",
       "   'igmp_snoop_policy': 'chiendetalus',\n",
       "   'mld_snoop_policy': 'bilbocquet',\n",
       "   'vrf': 'bob',\n",
       "   'tenant': 'nils',\n",
       "   'epr_policy': 'mangaboul',\n",
       "   'bd': 'tintin',\n",
       "   'bcastP': '225.1.156.64',\n",
       "   'enable_rogue_except_mac': 'no',\n",
       "   'mac_address': '00:22:BD:F8:19:FF',\n",
       "   'modTs': '2024-07-16T02:21:26.858+00:00',\n",
       "   'monPolDn': 'uni/tn-common/monepg-default',\n",
       "   'pcTag': '49153',\n",
       "   'rn': 'BD-tintin',\n",
       "   'scope': '2326529',\n",
       "   'seg': '16154554',\n",
       "   'uid': '15374',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a SUBNET to the BD',\n",
       "  'cisco.aci.aci_bd_subnet': {'tenant': 'nils',\n",
       "   'epr_policy': 'mangaboul',\n",
       "   'vrf': 'bob',\n",
       "   'bd': 'tintin',\n",
       "   'mask': 24,\n",
       "   'gateway': '10.10.10.1',\n",
       "   'modTs': '2024-07-06T04:21:54.805+00:00',\n",
       "   'monPolDn': 'uni/tn-common/monepg-default',\n",
       "   'rn': 'subnet-[10.10.10.1/24]',\n",
       "   'scope': 'public,shared',\n",
       "   'uid': '15374',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# safe version of the script, when needing a backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_yml(data, out_dir=None):\n",
    "    save_path = \"ansible_reconstructed.yml\" if out_dir is None else os.path.join(out_dir, \"ansible_reconstructed.yml\")\n",
    "\n",
    "    # here define default arguments (to delete)\n",
    "    default_args = ['', \"\", \"::\", \":all:\"]\n",
    "\n",
    "    # define exception list\n",
    "    exception_list = ['aci_access_span_src_group',\n",
    "                        'aci_bd',\n",
    "                        'aci_bd_dhcp_label',\n",
    "                        'aci_bd_subnet',\n",
    "                        'aci_domain_to_vlan_pool',\n",
    "                        'aci_epg_subnet',\n",
    "                        'aci_fabric_span_src_group',\n",
    "                        'aci_tenant_span_src_group',\n",
    "                        'aci_tenant_span_src_group_src']\n",
    "    \n",
    "    # here define duplicates list - handle dupes in values of class mappings\n",
    "    # key (class) : value (dict) -> key (parent class) : value (correct mapping)\n",
    "\n",
    "    duplicate_list = ['spanDestGrp', 'spanSrcGrp', 'spanSrc',\n",
    "                      'mgmtMaintP', 'spanRsSrcToPathEp', 'fvSubnet',\n",
    "                      'fvRsPathAtt', 'vzBrCP', 'dhcpRelayP',\n",
    "                      'infraRsVlanNs', 'fvRsSecInherited', 'l1PhysIf',\n",
    "                      'l2extInstP', 'mgmtOoB']\n",
    "\n",
    "    # TO DO\n",
    "    # finish this mapping\n",
    "    duplicate_map = {\n",
    "        # 'spanDestGrp': None,\n",
    "        # 'spanSrcGrp': None,\n",
    "        # 'spanSrc': None,\n",
    "        # 'mgmtMaintP': None,\n",
    "        # 'spanRsSrcToPathEp': None,\n",
    "        'fvSubnet': {'aci_epg': 'aci_epg_subnet',\n",
    "                     'aci_bd': 'aci_bd_subnet'},\n",
    "        # 'fvRsPathAtt': None,\n",
    "        'vzBrCP': \"aci_contract\",\n",
    "        # 'dhcpRelayP': None,\n",
    "        # 'infraRsVlanNs': None,\n",
    "        # 'fvRsSecInherited': None,\n",
    "        # 'l1PhysIf': None,\n",
    "        # 'l2extInstP': None,\n",
    "        # 'mgmtOoB': None\n",
    "        }\n",
    "    \n",
    "    def map_json_to_ansible(json_data, key, map):\n",
    "        try:\n",
    "            new_key = map[key]\n",
    "            json_data[new_key] = json_data.pop(key) # replace with ansible term\n",
    "        except(KeyError): # no match found, skip\n",
    "            pass\n",
    "\n",
    "    def remove_isNotConfigurable(key, delete_key_list):\n",
    "        try:\n",
    "            if isConfigurableMap[key] == False:\n",
    "                delete_key_list.append(key)\n",
    "            else:\n",
    "                pass\n",
    "        except(KeyError):\n",
    "            pass\n",
    "\n",
    "    # helper method to navigate the exception dictionary\n",
    "    def map_if_duplicate(child, parent = None):\n",
    "        out = None\n",
    "        try:\n",
    "            out = duplicate_map[child][parent]\n",
    "        except(KeyError):\n",
    "            out = duplicate_map[child] # means there is no exception with the parent\n",
    "        return out\n",
    "\n",
    "    # simple method to check if a key in in the exception list\n",
    "    # need to run this stuff before mapping anything - mapping is ambiguous\n",
    "    def isduplicate(key):\n",
    "        return key in duplicate_list\n",
    "\n",
    "    def isdefault(parent_key, key, value, map):\n",
    "        try:\n",
    "            return value == map[parent_key][key] # means attribute has a default value\n",
    "        except(KeyError):\n",
    "            return False\n",
    "        \n",
    "    def isexception(key): # checks if key in exceptions\n",
    "        try:\n",
    "            return classToAnsible[key] in exception_list\n",
    "        except(KeyError):\n",
    "            return False\n",
    "\n",
    "    # def isrequired(parent_key, key, map):\n",
    "    #     if key in \n",
    "\n",
    "    # process data recursively\n",
    "    # we need to track many parent-child keys, including some of sublists etc\n",
    "    def process(data, parent_key:str = None, children_parent_key:str = None, attribute_parent_key:str = None, default_map:dict = defaults, dn:dict = {}) -> dict:\n",
    "        \"\"\"\n",
    "\n",
    "        Handles mapping of \n",
    "        - classes to ansible\n",
    "        - class parameters to ansible\n",
    "\n",
    "        Gets rid of the \"attributes\" field found in the JSON config \n",
    "\n",
    "        Gets rid of any fields with default values\n",
    "\n",
    "        Handles duplicates in mappings\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        changes = []\n",
    "\n",
    "        yml_tasks = [] # we will also need a list of the nested dictionaries for yml correct format\n",
    "\n",
    "        if isinstance(data, dict):\n",
    "            keys_to_delete = [] # maintain this list outside any loop, prevents \"changed size\" errors\n",
    "\n",
    "            for key, value in data.items():\n",
    "\n",
    "                # handle dn - name of parent in child, grandchild etc etc\n",
    "                if isinstance(value, dict) and \"children\" in value.keys():\n",
    "                    dn_key = reverseAliases[classToAnsible[key]][\"name\"][:-1]\n",
    "                    dn_val = data[key]['attributes'][\"name\"]\n",
    "                    dn[dn_key] = dn_val\n",
    "\n",
    "                # all CLASSES are handled, exceptions..\n",
    "                # TO DO -> handle exceptions like \"changes\"\n",
    "                # also not quite sure everything we are looking for is exclusively under \"children\" ...\n",
    "                if key == \"children\":\n",
    "                    children_parent_key = parent_key\n",
    "\n",
    "                    # children ALWAYS contains a nested list of nested dictionaries\n",
    "                    for item in value:\n",
    "                        for chld_key, chld_value in item.items():\n",
    "\n",
    "                            # the last element of each tuple in \"changes\" is an integer\n",
    "                            # this is ONLY TO IDENTIFY WHICH TYPE OF CHANGE IS NEEDED\n",
    "\n",
    "                            # handle duplicate mappings FIRST\n",
    "                            if isduplicate(chld_key):\n",
    "                                changes.append((children_parent_key, chld_key, chld_value, 0))\n",
    "\n",
    "                # all PARAMETERS are processed and mapped if needed\n",
    "                elif key == \"attributes\": # these are all the parameters of the classes\n",
    "                    attribute_parent_key = parent_key\n",
    "\n",
    "                    if isexception(parent_key):\n",
    "                        # TYPE 1 EXCEPTIONS -> ADD PARAMS WHICH ARE FOUND IN SUBCLASSES (handled same as type2 actually)\n",
    "                        try:\n",
    "                            for param, path in exceptions[classToAnsible[parent_key]].items():\n",
    "                                for item in data['children']: # it seems \"children\" is almost always found here\n",
    "                                    if path[0] in item.keys():\n",
    "                                        changes.append((parent_key, param, item[path[0]][path[1]][path[2]], 2))\n",
    "\n",
    "                        except(KeyError) as e:\n",
    "                            print(f\"KeyError encountered: {e}\")\n",
    "                            pass\n",
    "\n",
    "                    # TYPE 2 -> fix the dn attributes missing from children classes \n",
    "                    if len(dn) > 0:\n",
    "                        for dn_key, dn_val in dn.items():\n",
    "                            print(dn_key, dn_val)\n",
    "                            changes.append((attribute_parent_key, dn_key, dn_val, 2))\n",
    "\n",
    "                    # TYPE 2 CHANGES -> ATTRIBUTES FIELD REMOVAL, REMOVAL OF DEFAULTS\n",
    "                    # append all non default params to \"changes\" - mapping and deletion is done here\n",
    "                    for attr_key, attr_value in value.items(): # here empty values are also handled, eg if default then don't change\n",
    "                        if attr_value not in default_args and not isdefault(attribute_parent_key, attr_key, attr_value, default_map):\n",
    "\n",
    "                            # proper to fv_subnet once again? \n",
    "                            # new exception found with \"ip\" -> creates a mask\n",
    "                            if attr_key == \"ip\":\n",
    "                                changes.append((attribute_parent_key, 'mask', int(attr_value[-2:]), 2))\n",
    "\n",
    "                            attr_value = attr_value if attr_key != \"ip\" else attr_value[:-3]\n",
    "\n",
    "                            changes.append((attribute_parent_key, attr_key, attr_value, 2)) # appends a tuple\n",
    "\n",
    "                            # atm hardcoding \"present\" into yml, change later if needed\n",
    "                            changes.append((attribute_parent_key, 'state', 'present', 2))\n",
    "\n",
    "                    keys_to_delete.append(\"attributes\") # can append key too\n",
    "\n",
    "                # any exception will be caught here and will crash the entire program\n",
    "                # therefore we want no exceptions\n",
    "                if isinstance(value, (dict, list)):\n",
    "                    try:\n",
    "                        process(value, key, attribute_parent_key, dn)\n",
    "                    except (KeyError, TypeError) as e:\n",
    "                        print(f\"Error processing key {key}: {e}\")\n",
    "                        pass\n",
    "\n",
    "                if isinstance(value, dict) and not value:\n",
    "                    keys_to_delete.append(key)\n",
    "\n",
    "                remove_isNotConfigurable(key, keys_to_delete) # change to boolean check? \n",
    "\n",
    "            # any modification to the dict can only be made outside the loops\n",
    "            for key in keys_to_delete:\n",
    "                del data[key]\n",
    "\n",
    "            # use the mapping function\n",
    "            for key in list(data.keys()):\n",
    "                if key not in duplicate_list: # mapping done elsewhere for dupes\n",
    "                    map_json_to_ansible(data, key, classToAnsible)\n",
    "\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                if isinstance(item, (dict, list)):\n",
    "                    process(item, parent_key, attribute_parent_key, dn)\n",
    "\n",
    "        # accessing keys in \"data\" instead of passing through a parent_key works\n",
    "        # BECAUSE OF RECURSION, we are handling nested dictionaries as \"data\" everytime !!!!!!\n",
    "        for change in changes:\n",
    "            parent_key, child_key, child_value, change_type = change  # \"change\" is a 3x tuple\n",
    "            if change_type == 2: # ATTRIBUTES parent key\n",
    "                try:\n",
    "                    new_key = reverseAliases[classToAnsible[parent_key]][child_key]\n",
    "                    data[new_key] = child_value\n",
    "                    if child_key in data and new_key != child_key: # UNSURE if this is necessary anymore ..\n",
    "                        del data[child_key]\n",
    "                except KeyError:\n",
    "                    data[child_key] = child_value\n",
    "    \n",
    "            # DOUBLE CHECK logic here, otherwise seems to work as expected\n",
    "            # also can get rid of the whole \"CHILDREN\" key and move all upwards when we need it, only issue is how does this translate in yml\n",
    "            # FOR NOW keep \"children\" key as it helps with ordering everything correctly\n",
    "            elif change_type == 0: # CHILDREN parent key, DUPLICATE CASES\n",
    "                try:\n",
    "                    new_key = map_if_duplicate(child_key, classToAnsible[parent_key])\n",
    "                    data['children'][0][new_key] = child_value\n",
    "                    if child_key in data['children'][0]: # is this always the case? 0 idx? double check logic\n",
    "                        del data['children'][0][child_key]\n",
    "                except(KeyError):\n",
    "                    pass\n",
    "\n",
    "        return data\n",
    "\n",
    "    # this function gets rid of empty structures in the output, think of {} for example\n",
    "    # code is from GPT\n",
    "    def remove_empty_dicts(data):\n",
    "        if isinstance(data, dict):\n",
    "            return {k: remove_empty_dicts(v) for k, v in data.items() if remove_empty_dicts(v)} # see return of function for why this works\n",
    "        elif isinstance(data, list):\n",
    "            for idx, item in enumerate(data):\n",
    "                if isinstance(item, dict) and len(item) == 0:\n",
    "                    data.pop(idx)\n",
    "                else:\n",
    "                    data[idx] = remove_empty_dicts(item)\n",
    "            return data\n",
    "        else:\n",
    "            return data # this basically evaluates to false when the structure is None\n",
    "\n",
    "    # process the initial data\n",
    "    a = process(data)\n",
    "\n",
    "    # delete the empty dictionaries\n",
    "    b = remove_empty_dicts(a)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regex testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "class YAMLItem:\n",
    "    def __init__(self, key, value, parent=None):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "\n",
    "        if isinstance(value, dict):\n",
    "            for k, v in value.items():\n",
    "                self.children.append(YAMLItem(k, v, parent=self))\n",
    "        elif isinstance(value, list):\n",
    "            for v in value:\n",
    "                self.children.append(YAMLItem(None, v, parent=self))\n",
    "\n",
    "    def is_duplicate(self, duplicate_list):\n",
    "        return self.key in duplicate_list\n",
    "\n",
    "    def is_default(self, default_map, default_args):\n",
    "        if self.parent and isinstance(self.parent.value, dict):\n",
    "            try:\n",
    "                return self.value == default_map[self.parent.key][self.key] or self.value in default_args\n",
    "            except KeyError:\n",
    "                return False\n",
    "        return False\n",
    "\n",
    "    def is_exception(self, class_to_ansible, exception_list):\n",
    "        try:\n",
    "            return class_to_ansible[self.key] in exception_list\n",
    "        except KeyError:\n",
    "            return False\n",
    "\n",
    "    def map_key(self, class_to_ansible, reverse_aliases):\n",
    "        if self.key in class_to_ansible:\n",
    "            self.key = class_to_ansible[self.key]\n",
    "\n",
    "    def remove_empty_dicts(self):\n",
    "        if isinstance(self.value, dict):\n",
    "            self.value = {k: v for k, v in self.value.items() if v}\n",
    "            for child in self.children:\n",
    "                child.remove_empty_dicts()\n",
    "\n",
    "        elif isinstance(self.value, list):\n",
    "            self.value = [v for v in self.value if v]\n",
    "            for child in self.children:\n",
    "                child.remove_empty_dicts()\n",
    "\n",
    "    def reconstruct(self):\n",
    "        if isinstance(self.value, dict):\n",
    "            self.value = {child.key: child.value for child in self.children}\n",
    "\n",
    "    def to_dict(self):\n",
    "        if self.key:\n",
    "            return {self.key: self.value}\n",
    "        return self.value\n",
    "\n",
    "class YAMLProcessor:\n",
    "    def __init__(self, data, out_dir=None):\n",
    "        self.data = data\n",
    "        self.out_dir = out_dir or os.getcwd()\n",
    "        self.default_args = ['', \"\", \"::\", \":all:\"] # adapt if more exceptions are found\n",
    "        self.exception_list = [\n",
    "            'aci_access_span_src_group', 'aci_bd', 'aci_bd_dhcp_label', 'aci_bd_subnet',\n",
    "            'aci_domain_to_vlan_pool', 'aci_epg_subnet', 'aci_fabric_span_src_group',\n",
    "            'aci_tenant_span_src_group', 'aci_tenant_span_src_group_src'\n",
    "        ]\n",
    "\n",
    "        self.duplicate_list = [\n",
    "            'spanDestGrp', 'spanSrcGrp', 'spanSrc', 'mgmtMaintP', 'spanRsSrcToPathEp',\n",
    "            'fvSubnet', 'fvRsPathAtt', 'vzBrCP', 'dhcpRelayP', 'infraRsVlanNs',\n",
    "            'fvRsSecInherited', 'l1PhysIf', 'l2extInstP', 'mgmtOoB'\n",
    "        ]\n",
    "\n",
    "        self.duplicate_map = { # need to complete this one with all the duplicates at some stage\n",
    "            'fvSubnet': {'aci_epg': 'aci_epg_subnet', 'aci_bd': 'aci_bd_subnet'},\n",
    "            'vzBrCP': \"aci_contract\"\n",
    "        }\n",
    "\n",
    "        self.class_to_ansible = classToAnsible\n",
    "        self.reverse_aliases = reverseAliases\n",
    "\n",
    "    def map_if_duplicate(self, child, parent=None):\n",
    "        try:\n",
    "            return self.duplicate_map[child][parent]\n",
    "        except KeyError:\n",
    "            return self.duplicate_map.get(child, child)\n",
    "\n",
    "    def process_item(self, item):\n",
    "        if isinstance(item.value, dict):\n",
    "            for child in item.children:\n",
    "                self.process_item(child)\n",
    "\n",
    "    def remove_empty_dicts(self, item):\n",
    "        item.remove_empty_dicts()\n",
    "\n",
    "    def reconstruct(self, item):\n",
    "        item.reconstruct()\n",
    "\n",
    "    def to_dict(self, item):\n",
    "        return item.to_dict()\n",
    "\n",
    "    def save_to_yaml(self, data):\n",
    "        save_path = os.path.join(self.out_dir, \"ansible_reconstructed.yml\")\n",
    "        with open(save_path, 'w') as file:\n",
    "            yaml.dump(data, file, default_flow_style=False)\n",
    "        print(f\"YAML file has been saved to {save_path}\")\n",
    "\n",
    "    def process(self):\n",
    "        root_item = YAMLItem(None, self.data)\n",
    "        self.process_item(root_item)\n",
    "        self.remove_empty_dicts(root_item)\n",
    "        self.reconstruct(root_item)\n",
    "        data = self.to_dict(root_item)\n",
    "        self.save_to_yaml(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError encountered: 'children'\n",
      "KeyError encountered: 'children'\n",
      "KeyError encountered: 'children'\n",
      "KeyError encountered: 'children'\n",
      "YAML file has been saved to ansible-reconstructed.yml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from mappings import classToAnsible, ansibleToClass # need to get the mapping to ansible from json\n",
    "import yaml\n",
    "import pprint\n",
    "from isConfigurableMap import isConfigurableMap # need to get the \n",
    "from defaultClassAttrValues import defaults\n",
    "from exceptionDict import exceptions\n",
    "from requiredParamsAliasesMap import requiredParamsAliases, reverse_alias_map\n",
    "\n",
    "# define all the paths here\n",
    "PATH_TO_SAVE = \"ansible-reconstructed.yml\"\n",
    "PATH_TO_JSON = \"tn-dev-test.json\"\n",
    "PATH_TO_CREDENTIALS = \"\"\n",
    "\n",
    "### start of the main function ###\n",
    "reverseAliases = reverse_alias_map(requiredParamsAliases)\n",
    "\n",
    "# this will be refactored at some stage, maybe some OOP or just cleaned, for now it does what I need it to\n",
    "\n",
    "def reconstruct_yml(data, out_dir=None):\n",
    "    save_path = \"ansible_reconstructed.yml\" if out_dir is None else os.path.join(out_dir, \"ansible_reconstructed.yml\")\n",
    "\n",
    "    # here define default arguments (to delete)\n",
    "    default_args = ['', \"\", \"::\", \":all:\"]\n",
    "\n",
    "    # invisible_arguments\n",
    "    invisible_args = [\"annotation\", \"dn\", \"rn\", \"uid\", \"modTs\", \"monPolDn\", \"seg\", \"pcTag\", \"userdom\", \"tDn\", \"filter_nam\"] # adjust as needed\n",
    "\n",
    "    # define exception list\n",
    "    exception_list = ['aci_access_span_src_group',\n",
    "                        'aci_bd',\n",
    "                        'aci_bd_dhcp_label',\n",
    "                        'aci_bd_subnet',\n",
    "                        'aci_domain_to_vlan_pool',\n",
    "                        'aci_epg_subnet',\n",
    "                        'aci_fabric_span_src_group',\n",
    "                        'aci_tenant_span_src_group',\n",
    "                        'aci_tenant_span_src_group_src']\n",
    "    \n",
    "    # here define duplicates list - handle dupes in values of class mappings\n",
    "    # key (class) : value (dict) -> key (parent class) : value (correct mapping)\n",
    "\n",
    "    duplicate_list = ['spanDestGrp', 'spanSrcGrp', 'spanSrc',\n",
    "                      'mgmtMaintP', 'spanRsSrcToPathEp', 'fvSubnet',\n",
    "                      'fvRsPathAtt', 'vzBrCP', 'dhcpRelayP',\n",
    "                      'infraRsVlanNs', 'fvRsSecInherited', 'l1PhysIf',\n",
    "                      'l2extInstP', 'mgmtOoB']\n",
    "\n",
    "    # TO DO\n",
    "    # finish this mapping\n",
    "    duplicate_map = {\n",
    "        # 'spanDestGrp': None,\n",
    "        # 'spanSrcGrp': None,\n",
    "        # 'spanSrc': None,\n",
    "        # 'mgmtMaintP': None,\n",
    "        # 'spanRsSrcToPathEp': None,\n",
    "        'fvSubnet': {'aci_epg': 'aci_epg_subnet',\n",
    "                     'aci_bd': 'aci_bd_subnet'},\n",
    "        # 'fvRsPathAtt': None,\n",
    "        'vzBrCP': \"aci_contract\",\n",
    "        # 'dhcpRelayP': None,\n",
    "        # 'infraRsVlanNs': None,\n",
    "        # 'fvRsSecInherited': None,\n",
    "        # 'l1PhysIf': None,\n",
    "        # 'l2extInstP': None,\n",
    "        # 'mgmtOoB': None\n",
    "        }\n",
    "    \n",
    "    def map_json_to_ansible(json_data, key, map):\n",
    "        try:\n",
    "            new_key = map[key]\n",
    "            json_data[new_key] = json_data.pop(key) # replace with ansible term\n",
    "        except(KeyError): # no match found, skip\n",
    "            pass\n",
    "\n",
    "    def remove_isNotConfigurable(key, delete_key_list):\n",
    "        try:\n",
    "            if isConfigurableMap[key] == False:\n",
    "                delete_key_list.append(key)\n",
    "            else:\n",
    "                pass\n",
    "        except(KeyError):\n",
    "            pass\n",
    "\n",
    "    # helper method to navigate the exception dictionary\n",
    "    def map_if_duplicate(child, parent = None):\n",
    "        out = None\n",
    "        try:\n",
    "            out = duplicate_map[child][parent]\n",
    "        except(KeyError):\n",
    "            out = duplicate_map[child] # means there is no exception with the parent\n",
    "        return out\n",
    "\n",
    "    # simple method to check if a key in in the exception list\n",
    "    # need to run this stuff before mapping anything - mapping is ambiguous\n",
    "    def isduplicate(key):\n",
    "        return key in duplicate_list\n",
    "\n",
    "    def isdefault(parent_key, key, value, map):\n",
    "        try:\n",
    "            return value == map[parent_key][key] # means attribute has a default value\n",
    "        except(KeyError):\n",
    "            return False\n",
    "        \n",
    "    def isexception(key): # checks if key in exceptions\n",
    "        try:\n",
    "            return classToAnsible[key] in exception_list\n",
    "        except(KeyError):\n",
    "            return False\n",
    "\n",
    "    def isfullydefault(val, parent_key, default_map, second_default_map):\n",
    "        try:\n",
    "            # convert defaults to sets \n",
    "            default_values_set = set(default_map[parent_key].values())\n",
    "            second_default_values_set = set(second_default_map)\n",
    "            \n",
    "            # combine default args and default mapping\n",
    "            combined_default_values_set = default_values_set.union(second_default_values_set)\n",
    "            \n",
    "            # to set \n",
    "            val_set = set(val)\n",
    "            \n",
    "            # check if subset\n",
    "            return val_set.issubset(combined_default_values_set)\n",
    "        except KeyError: # anything which is not \"fv\" is here atm\n",
    "            return True # change based on desired behavior\n",
    "        \n",
    "    def save_to_yaml(save_path, data):\n",
    "        # save_path = os.path.join(save_path, \"ansible_reconstructed.yml\")\n",
    "        with open(\"ansible_reconstructed.yml\", 'w') as file:\n",
    "            yaml.dump(a, file, default_flow_style = False, sort_keys = False)\n",
    "        print(f\"YAML file has been saved to ansible_reconstructed.yml\")\n",
    "\n",
    "    # process data recursively\n",
    "    # we need to track many parent-child keys, including some of sublists etc\n",
    "    def process(data,\n",
    "                parent_key:str = None,\n",
    "                grandparent_key:str = None,\n",
    "                default_map:dict = defaults,\n",
    "                dn:dict = {},\n",
    "                dn_key_stack:list = []) -> dict:\n",
    "        \"\"\"\n",
    "\n",
    "        Handles mapping of \n",
    "        - classes to ansible\n",
    "        - class parameters to ansible\n",
    "\n",
    "        Gets rid of the \"attributes\" field found in the JSON config \n",
    "\n",
    "        Gets rid of any fields with default values\n",
    "\n",
    "        Handles duplicates in mappings\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        changes = []\n",
    "\n",
    "        if isinstance(data, dict):\n",
    "            keys_to_delete = [] # maintain this list outside any loop, prevents \"changed size\" errors\n",
    "\n",
    "            for key, value in data.items():\n",
    "\n",
    "                # all CLASSES are handled, exceptions..\n",
    "                # TO DO -> handle exceptions like \"changes\"\n",
    "                # also not quite sure everything we are looking for is exclusively under \"children\" ...\n",
    "                if key == \"children\":\n",
    "\n",
    "                    # children ALWAYS contains a nested list of nested dictionaries\n",
    "                    for item in value:\n",
    "                        for chld_key, chld_value in item.items():\n",
    "\n",
    "                            # the last element of each tuple in \"changes\" is an integer\n",
    "                            # this is ONLY TO IDENTIFY WHICH TYPE OF CHANGE IS NEEDED\n",
    "\n",
    "                            # handle duplicate mappings FIRST\n",
    "                            if isduplicate(chld_key):\n",
    "                                changes.append((parent_key, chld_key, chld_value, 0))\n",
    "\n",
    "                # all PARAMETERS are processed and mapped if needed\n",
    "                elif key == \"attributes\": # these are all the parameters of the classes\n",
    "\n",
    "                    # check if all attributes are default; if so, skip processing entirely\n",
    "                    # empty dictionaries function will take care of it\n",
    "                    if not isfullydefault(value.values(), parent_key, defaults, default_args):\n",
    "\n",
    "                        if isexception(parent_key):\n",
    "\n",
    "                            # TYPE 1 EXCEPTIONS -> ADD PARAMS WHICH ARE FOUND IN SUBCLASSES (handled same as type2 actually)\n",
    "                            try:\n",
    "                                for param, path in exceptions[classToAnsible[parent_key]].items():\n",
    "                                    for item in data['children']: # it seems \"children\" is almost always found here\n",
    "                                        if path[0] in item.keys():\n",
    "                                            changes.append((parent_key, param, item[path[0]][path[1]][path[2]], 2))\n",
    "\n",
    "                                            #######\n",
    "                                            # path[0] is the exception class we need to get rid of, maybe through the changes system\n",
    "                                            #######\n",
    "\n",
    "                            except(KeyError) as e:\n",
    "                                print(f\"KeyError encountered: {e}\")\n",
    "                                pass\n",
    "\n",
    "                        # TYPE 2 CHANGES -> ATTRIBUTES FIELD REMOVAL, REMOVAL OF DEFAULTS\n",
    "                        # append all non default params to \"changes\" - mapping and deletion is done here\n",
    "                        for attr_key, attr_value in value.items(): # here empty values are also handled, eg if default then don't change\n",
    "                            if attr_key not in invisible_args and attr_value not in default_args and not isdefault(parent_key, attr_key, attr_value, default_map):\n",
    "\n",
    "                                # proper to fv_subnet once again?\n",
    "                                # new exception found with \"ip\" -> creates a mask\n",
    "                                if attr_key == \"ip\":\n",
    "                                    attr_key = \"gateway\"\n",
    "                                    changes.append((parent_key, 'mask', int(attr_value[-2:]), 2))\n",
    "\n",
    "                                attr_value = attr_value if attr_key != \"gateway\" else attr_value[:-3]\n",
    "\n",
    "                                changes.append((parent_key, attr_key, attr_value, 2)) # appends a tuple\n",
    "\n",
    "                        # atm hardcoding \"present\" into yml, change later if needed\n",
    "                        changes.append((parent_key, 'state', 'present', 2))\n",
    "\n",
    "                    keys_to_delete.append(\"attributes\") # can append key too\n",
    "\n",
    "                # any exception will be caught here and will crash the entire program\n",
    "                # therefore we want no exceptions\n",
    "                if isinstance(value, (dict, list)):\n",
    "                    try:\n",
    "                        process(data = value, parent_key = key, grandparent_key = parent_key)\n",
    "    \n",
    "                    except (KeyError) as e:\n",
    "                        print(f\"Error processing key {key}: {e}\")\n",
    "                        pass\n",
    "\n",
    "                if isinstance(value, dict) and not value:\n",
    "                    keys_to_delete.append(key)\n",
    "\n",
    "                remove_isNotConfigurable(key, keys_to_delete) # change to boolean check? \n",
    "\n",
    "            # any modification to the dict can only be made outside the loops\n",
    "            for key in keys_to_delete:\n",
    "                try:\n",
    "                    del data[key]\n",
    "                except(KeyError):\n",
    "                    pass\n",
    "\n",
    "            # use the mapping function\n",
    "            for key in list(data.keys()):\n",
    "                if key not in duplicate_list: # mapping done elsewhere for dupes\n",
    "                    map_json_to_ansible(data, key, classToAnsible)\n",
    "\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                if isinstance(item, (dict, list)):\n",
    "                    process(data = item, parent_key = parent_key, grandparent_key = grandparent_key)\n",
    "\n",
    "        # accessing keys in \"data\" instead of passing through a parent_key works\n",
    "        # BECAUSE OF RECURSION, we are handling nested dictionaries as \"data\" everytime !!!!!!\n",
    "        for change in changes:\n",
    "            parent_key, child_key, child_value, change_type = change  # \"change\" is a 3x tuple\n",
    "            if change_type == 2: # ATTRIBUTES parent key\n",
    "                try:\n",
    "                    new_key = reverseAliases[classToAnsible[parent_key]][child_key]\n",
    "\n",
    "                    # at the moment no use for the required tag, can change later on if we need it somehow\n",
    "                    if new_key[-1] == \"*\":\n",
    "                        new_key = new_key[:-1]\n",
    "\n",
    "                    data[new_key] = child_value\n",
    "                    if child_key in data and new_key != child_key: # UNSURE if this is necessary anymore ..\n",
    "                        del data[child_key]\n",
    "                except KeyError:\n",
    "                    data[child_key] = child_value\n",
    "\n",
    "            # DOUBLE CHECK logic here, otherwise seems to work as expected\n",
    "            # also can get rid of the whole \"CHILDREN\" key and move all upwards when we need it, only issue is how does this translate in yml\n",
    "            # FOR NOW keep \"children\" key as it helps with ordering everything correctly\n",
    "            elif change_type == 0: # CHILDREN parent key, DUPLICATE CASES\n",
    "                try:\n",
    "                    new_key = map_if_duplicate(child_key, classToAnsible[parent_key])\n",
    "                    data['children'][0][new_key] = child_value\n",
    "                    if child_key in data['children'][0]: # is this always the case? 0 idx? double check logic\n",
    "                        del data['children'][0][child_key]\n",
    "                except(KeyError):\n",
    "                    pass\n",
    "\n",
    "        return data\n",
    "\n",
    "    # this function gets rid of empty structures in the output, think of {} for example\n",
    "    # code is from GPT\n",
    "    def remove_empty_dicts(data):\n",
    "        if isinstance(data, dict):\n",
    "            return {k: remove_empty_dicts(v) for k, v in data.items() if remove_empty_dicts(v)} # see return of function for why this works\n",
    "        elif isinstance(data, list):\n",
    "            for idx, item in enumerate(data):\n",
    "                if isinstance(item, dict) and len(item) == 0:\n",
    "                    data.pop(idx)\n",
    "                else:\n",
    "                    data[idx] = remove_empty_dicts(item)\n",
    "            return data\n",
    "        else:\n",
    "            return data # this basically evaluates to false when the structure is None\n",
    "\n",
    "    # this function rebuilds the DN attributes, when parent attributes are needed etc\n",
    "    # cannot figure out way to fix this withing the loop atm, this does the trick just fine\n",
    "    # def build_dn(data, ancestors=[], parent_child_map = {}):\n",
    "    #     if isinstance(data, dict):\n",
    "    #         for key, value in data.items():\n",
    "    #             if key != 'children' and isinstance(value, dict):\n",
    "    #                 if key not in parent_child_map:\n",
    "    #                     parent_child_map[key] = []\n",
    "    #                 parent_child_map[key].extend(ancestors)\n",
    "    #                 build_dn(value, ancestors + [key])\n",
    "    #             elif key == 'children':\n",
    "    #                 for child in value:\n",
    "    #                     build_dn(child, ancestors)\n",
    "\n",
    "    #     return parent_child_map\n",
    "\n",
    "    # this function gathers all hierarchical parameter names - further used in reconstruct function\n",
    "    # returns a dictionary with list values and string keys\n",
    "    def get_parent_attributes(data, \n",
    "                          parent_key=None, \n",
    "                          grandparent_key=None, \n",
    "                          great_grandparent_key=None, \n",
    "                          great_great_grandparent_key=None, \n",
    "                          parent_name=None, \n",
    "                          grandparent_name=None, \n",
    "                          great_grandparent_name=None, \n",
    "                          great_great_grandparent_name=None, \n",
    "                          changes=None):\n",
    "\n",
    "        if changes is None:\n",
    "            changes = {}\n",
    "\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                try:\n",
    "                    current_name = reverseAliases[key][\"name\"][:-1]  # remove mandatory tag\n",
    "                except KeyError:\n",
    "                    current_name = None\n",
    "\n",
    "                if parent_key == \"children\": # need to append all this info for later use - iterate over pairwise, will work just fine\n",
    "                    change = [i for i in [parent_name, grandparent_name, great_grandparent_name, great_great_grandparent_name, grandparent_key, great_great_grandparent_key] if i is not None]\n",
    "                    changes[key] = change\n",
    "\n",
    "                # could make it more clear somehow.. \n",
    "                get_parent_attributes(value, key, parent_key, grandparent_key, great_grandparent_key, \n",
    "                                    current_name, parent_name, grandparent_name, great_grandparent_name, changes)\n",
    "\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                get_parent_attributes(item, parent_key, grandparent_key, great_grandparent_key, great_great_grandparent_key, \n",
    "                                    parent_name, grandparent_name, great_grandparent_name, great_great_grandparent_name, changes)\n",
    "\n",
    "        return changes\n",
    "\n",
    "    # handle reconstruction of yml with recursion\n",
    "    # TO DO -> ADD REMVOVAL OF \"fvRs\" CLASSES, too hard to handle above due to recursive issues\n",
    "    def rebuild_yml(data, credentials_file = None, yml_list = [], parent_key = None, grandparent_key = None, dn_key_stack = [], dn = {}):\n",
    "\n",
    "        entry_dict = {}\n",
    "\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "\n",
    "                nested_dictionary = {}\n",
    "\n",
    "                # here restructuring is handled\n",
    "                if parent_key == \"children\" or parent_key == None:\n",
    "\n",
    "                    # bad trick to get rid of all non-aci modules\n",
    "                    if key[:3] == \"aci\":\n",
    "                        pass\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                    # set name to something generic\n",
    "                    key_name = key.split(\"_\")[1] if len(key.split(\"_\")) == 2 else key.split(\"_\")[2]\n",
    "                    if parent_key != None:\n",
    "                        grandparent_key_name = grandparent_key.split(\"_\")[1] if len(grandparent_key.split(\"_\")) == 2 else grandparent_key.split(\"_\")[2:]\n",
    "                        sentence = f\"add a {key_name.upper()} to the {grandparent_key_name.upper()}\"\n",
    "                    else:\n",
    "                        sentence = f\"create {key_name} on ACI using {key} module\"\n",
    "\n",
    "                    entry_dict[\"name\"] = sentence\n",
    "                    for subkey, subvalue in data[key].items():\n",
    "                        if subkey != \"children\":\n",
    "                            # print(key, subkey, subvalue)\n",
    "                            nested_dictionary[subkey] = subvalue\n",
    "                    entry_dict[\"cisco.aci.\" + key] = nested_dictionary\n",
    "                    entry_dict[\"delegate_to\"] = \"localhost\"\n",
    "\n",
    "                    yml_list.append(entry_dict)\n",
    "\n",
    "                if isinstance(value, dict):\n",
    "                    rebuild_yml(value, parent_key = key, grandparent_key = parent_key)\n",
    "\n",
    "                elif isinstance(value, list):\n",
    "                    for item in value:\n",
    "                        rebuild_yml(item, parent_key = key, grandparent_key = parent_key)\n",
    "\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                rebuild_yml(item, parent_key = key, grandparent_key = parent_key)\n",
    "\n",
    "        return yml_list\n",
    "\n",
    "    # process the initial data\n",
    "    a = process(data)\n",
    "\n",
    "    # delete the empty dictionaries\n",
    "    b = remove_empty_dicts(a)\n",
    "\n",
    "    c = get_parent_attributes(b)\n",
    "\n",
    "    fin = rebuild_yml(b)\n",
    "\n",
    "    return b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    with open(PATH_TO_JSON, 'r') as file:\n",
    "        y = json.load(file)\n",
    "\n",
    "    out = reconstruct_yml(y)\n",
    "\n",
    "    # save_path = os.path.join(save_path, \"ansible_reconstructed.yml\")\n",
    "    with open(PATH_TO_SAVE, 'w') as file:\n",
    "        yaml.dump(out, file, default_flow_style = False, sort_keys = False)\n",
    "\n",
    "    print(f\"YAML file has been saved to {PATH_TO_SAVE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aci_tenant': {'children': [{'aci_vrf': {'vrf': 'dev.dev-vrf',\n",
       "     'state': 'present'}},\n",
       "   {'aci_bd': {'children': [{'aci_bd_subnet': {'mask': 24,\n",
       "        'gateway': '10.1.10.1',\n",
       "        'state': 'present'}},\n",
       "      {'fvRsCtx': {'tnFvCtxName': 'dev.dev-vrf', 'state': 'present'}}],\n",
       "     'endpoint_retention_action': 'resolve',\n",
       "     'vrf': 'dev.dev-vrf',\n",
       "     'arp_flooding': 'yes',\n",
       "     'enable_rogue_except_mac': 'no',\n",
       "     'mac_address': '00:22:BD:F8:19:FF',\n",
       "     'bd': '10.1.10.0_24',\n",
       "     'l2_unknown_unicast': 'flood',\n",
       "     'state': 'present'}},\n",
       "   {'aci_bd': {'children': [{'aci_bd_subnet': {'mask': 24,\n",
       "        'gateway': '10.1.13.1',\n",
       "        'state': 'present'}},\n",
       "      {'fvRsCtx': {'tnFvCtxName': 'dev.dev-vrf', 'state': 'present'}}],\n",
       "     'endpoint_retention_action': 'resolve',\n",
       "     'vrf': 'dev.dev-vrf',\n",
       "     'arp_flooding': 'yes',\n",
       "     'enable_rogue_except_mac': 'no',\n",
       "     'mac_address': '00:22:BD:F8:19:FF',\n",
       "     'bd': '10.1.13.0_24',\n",
       "     'l2_unknown_unicast': 'flood',\n",
       "     'state': 'present'}},\n",
       "   {'aci_bd': {'children': [{'aci_bd_subnet': {'mask': 24,\n",
       "        'gateway': '10.1.11.1',\n",
       "        'state': 'present'}},\n",
       "      {'fvRsCtx': {'tnFvCtxName': 'dev.dev-vrf', 'state': 'present'}}],\n",
       "     'endpoint_retention_action': 'resolve',\n",
       "     'vrf': 'dev.dev-vrf',\n",
       "     'arp_flooding': 'yes',\n",
       "     'enable_rogue_except_mac': 'no',\n",
       "     'mac_address': '00:22:BD:F8:19:FF',\n",
       "     'bd': '10.1.11.0_24',\n",
       "     'l2_unknown_unicast': 'flood',\n",
       "     'state': 'present'}},\n",
       "   {'aci_bd': {'children': [{'aci_bd_subnet': {'mask': 24,\n",
       "        'gateway': '10.1.12.1',\n",
       "        'state': 'present'}},\n",
       "      {'fvRsCtx': {'tnFvCtxName': 'dev.dev-vrf', 'state': 'present'}}],\n",
       "     'endpoint_retention_action': 'resolve',\n",
       "     'vrf': 'dev.dev-vrf',\n",
       "     'arp_flooding': 'yes',\n",
       "     'enable_rogue_except_mac': 'no',\n",
       "     'mac_address': '00:22:BD:F8:19:FF',\n",
       "     'bd': '10.1.12.0_24',\n",
       "     'l2_unknown_unicast': 'flood',\n",
       "     'state': 'present'}},\n",
       "   {},\n",
       "   {'aci_ap': {'children': [{'aci_esg': {'children': [{'fvRsScope': {'tnFvCtxName': 'dev.dev-vrf',\n",
       "           'state': 'present'}},\n",
       "         {'aci_epg_to_contract_interface': {'tnVzCPIfName': 'to_common_l3out_to_core_ospf',\n",
       "           'state': 'present'}},\n",
       "         {'fvEPgSelector': {'matchEpgDn': 'uni/tn-dev/ap-network-segments/epg-10.1.11.0_24',\n",
       "           'state': 'present'}},\n",
       "         {'fvEPgSelector': {'matchEpgDn': 'uni/tn-dev/ap-network-segments/epg-10.1.10.0_24',\n",
       "           'state': 'present'}},\n",
       "         {'fvEPgSelector': {'matchEpgDn': 'uni/tn-dev/ap-network-segments/epg-10.1.12.0_24',\n",
       "           'state': 'present'}},\n",
       "         {'fvEPgSelector': {'matchEpgDn': 'uni/tn-dev/ap-network-segments/epg-10.1.13.0_24',\n",
       "           'state': 'present'}}],\n",
       "        'description': 'ESG used to group all endpoints from EPGs',\n",
       "        'esg': 'all-services',\n",
       "        'state': 'present'}},\n",
       "      {'aci_epg': {'children': [{'aci_epg_to_domain': {'allow_useg': 'useg',\n",
       "           'encap': 'vlan-2027',\n",
       "           'deploy_immediacy': 'immediate',\n",
       "           'number_of_ports': '0',\n",
       "           'primary_encap': 'vlan-2026',\n",
       "           'primaryEncapInner': 'unknown',\n",
       "           'resolution_immediacy': 'immediate',\n",
       "           'secondaryEncapInner': 'unknown',\n",
       "           'state': 'present'}},\n",
       "         {'fvRsBd': {'tnFvBDName': '10.1.13.0_24', 'state': 'present'}}],\n",
       "        'epg': '10.1.13.0_24',\n",
       "        'state': 'present'}},\n",
       "      {'aci_epg': {'children': [{'aci_epg_to_domain': {'allow_useg': 'useg',\n",
       "           'encap': 'vlan-2023',\n",
       "           'deploy_immediacy': 'immediate',\n",
       "           'number_of_ports': '0',\n",
       "           'primary_encap': 'vlan-2022',\n",
       "           'primaryEncapInner': 'unknown',\n",
       "           'resolution_immediacy': 'immediate',\n",
       "           'secondaryEncapInner': 'unknown',\n",
       "           'state': 'present'}},\n",
       "         {'fvRsBd': {'tnFvBDName': '10.1.11.0_24', 'state': 'present'}}],\n",
       "        'epg': '10.1.11.0_24',\n",
       "        'state': 'present'}},\n",
       "      {'aci_epg': {'children': [{'aci_epg_to_domain': {'allow_useg': 'useg',\n",
       "           'encap': 'vlan-2021',\n",
       "           'deploy_immediacy': 'immediate',\n",
       "           'number_of_ports': '0',\n",
       "           'primary_encap': 'vlan-2020',\n",
       "           'primaryEncapInner': 'unknown',\n",
       "           'resolution_immediacy': 'immediate',\n",
       "           'secondaryEncapInner': 'unknown',\n",
       "           'state': 'present'}},\n",
       "         {'fvRsBd': {'tnFvBDName': '10.1.10.0_24', 'state': 'present'}}],\n",
       "        'epg': '10.1.10.0_24',\n",
       "        'state': 'present'}},\n",
       "      {'aci_epg': {'children': [{'aci_epg_to_domain': {'allow_useg': 'useg',\n",
       "           'encap': 'vlan-2025',\n",
       "           'deploy_immediacy': 'immediate',\n",
       "           'number_of_ports': '0',\n",
       "           'primary_encap': 'vlan-2024',\n",
       "           'primaryEncapInner': 'unknown',\n",
       "           'resolution_immediacy': 'immediate',\n",
       "           'secondaryEncapInner': 'unknown',\n",
       "           'state': 'present'}},\n",
       "         {'fvRsBd': {'tnFvBDName': '10.1.12.0_24', 'state': 'present'}}],\n",
       "        'epg': '10.1.12.0_24',\n",
       "        'state': 'present'}}],\n",
       "     'ap': 'network-segments',\n",
       "     'state': 'present'}}],\n",
       "  'tenant': 'dev_mart',\n",
       "  'state': 'present'}}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_siblings(data, merge = {}):\n",
    "    yml_list_map = {} # save all mappings here, map outside main loop (or change during iteration error)\n",
    "    variation_list = []\n",
    "    nested_dict = {}\n",
    "    nested_key = None\n",
    "\n",
    "    for module in data:\n",
    "        aci_class = list(module.keys())[1].split(\".\")[2] # aci_tenant, aci_vrf, aci_bd ...\n",
    "\n",
    "        if aci_class in merge:\n",
    "            for subkey, subvalue in module.items():\n",
    "                if subkey.split(\".\")[0] == \"cisco\": # only go in attributes\n",
    "                    for subsubkey, subsubvalue in subvalue.items():\n",
    "                        try: # id and map merge\n",
    "                            if subsubvalue != comparable[subsubkey]:\n",
    "                                # print(\"change detected : \", subsubkey, subsubvalue, comparable[subsubkey])\n",
    "                                if comparable[subsubkey] not in variation_list:\n",
    "                                    variation_list.append(comparable[subsubkey])\n",
    "                                    nested_key = subsubkey\n",
    "                                variation_list.append(subsubvalue)\n",
    "                        except(KeyError):\n",
    "                            pass\n",
    "\n",
    "            print(aci_class)\n",
    "            print(variation_list, nested_key)\n",
    "\n",
    "            if nested_key: # not None\n",
    "                nested_dict[nested_key] = variation_list.copy()  # Use .copy() to avoid mutable reference issues\n",
    "\n",
    "                print(nested_dict)\n",
    "\n",
    "                yml_list_map[aci_class] = nested_dict.copy()  # Use .copy() to avoid mutable reference issues\n",
    "\n",
    "                print(\"\\n\")\n",
    "\n",
    "        # in this block we simply are in another class - say aci_bd -> aci_epg\n",
    "        # therefore we need to reset everything\n",
    "        if aci_class not in merge:\n",
    "            merge[aci_class] = module\n",
    "            comparable = merge[aci_class][\"cisco.aci.\" + aci_class]\n",
    "            variation_list = []  # Create a new list\n",
    "            nested_dict = {}  # Create a new dictionary\n",
    "            nested_key = None\n",
    "\n",
    "\n",
    "        # TO DO \n",
    "        # apply all changes (build the loop)\n",
    "\n",
    "    return yml_list_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aci_bd\n",
      "[] None\n",
      "aci_bd_subnet\n",
      "['10.1.10.1', '10.1.13.1'] gateway\n",
      "{'gateway': ['10.1.10.1', '10.1.13.1']}\n",
      "\n",
      "\n",
      "aci_bd\n",
      "['10.1.10.1', '10.1.13.1'] gateway\n",
      "{'gateway': ['10.1.10.1', '10.1.13.1']}\n",
      "\n",
      "\n",
      "aci_bd_subnet\n",
      "['10.1.10.1', '10.1.13.1', '10.1.11.1'] gateway\n",
      "{'gateway': ['10.1.10.1', '10.1.13.1', '10.1.11.1']}\n",
      "\n",
      "\n",
      "aci_bd\n",
      "['10.1.10.1', '10.1.13.1', '10.1.11.1'] gateway\n",
      "{'gateway': ['10.1.10.1', '10.1.13.1', '10.1.11.1']}\n",
      "\n",
      "\n",
      "aci_bd_subnet\n",
      "['10.1.10.1', '10.1.13.1', '10.1.11.1', '10.1.12.1'] gateway\n",
      "{'gateway': ['10.1.10.1', '10.1.13.1', '10.1.11.1', '10.1.12.1']}\n",
      "\n",
      "\n",
      "aci_epg\n",
      "[] None\n",
      "aci_epg_to_domain\n",
      "['vlan-2027', 'vlan-2023', 'vlan-2026', 'vlan-2022'] primary_encap\n",
      "{'primary_encap': ['vlan-2027', 'vlan-2023', 'vlan-2026', 'vlan-2022']}\n",
      "\n",
      "\n",
      "aci_epg\n",
      "['vlan-2027', 'vlan-2023', 'vlan-2026', 'vlan-2022'] primary_encap\n",
      "{'primary_encap': ['vlan-2027', 'vlan-2023', 'vlan-2026', 'vlan-2022']}\n",
      "\n",
      "\n",
      "aci_epg_to_domain\n",
      "['vlan-2027', 'vlan-2023', 'vlan-2026', 'vlan-2022', 'vlan-2021', 'vlan-2020'] primary_encap\n",
      "{'primary_encap': ['vlan-2027', 'vlan-2023', 'vlan-2026', 'vlan-2022', 'vlan-2021', 'vlan-2020']}\n",
      "\n",
      "\n",
      "aci_epg\n",
      "['vlan-2027', 'vlan-2023', 'vlan-2026', 'vlan-2022', 'vlan-2021', 'vlan-2020'] primary_encap\n",
      "{'primary_encap': ['vlan-2027', 'vlan-2023', 'vlan-2026', 'vlan-2022', 'vlan-2021', 'vlan-2020']}\n",
      "\n",
      "\n",
      "aci_epg_to_domain\n",
      "['vlan-2027', 'vlan-2023', 'vlan-2026', 'vlan-2022', 'vlan-2021', 'vlan-2020', 'vlan-2025', 'vlan-2024'] primary_encap\n",
      "{'primary_encap': ['vlan-2027', 'vlan-2023', 'vlan-2026', 'vlan-2022', 'vlan-2021', 'vlan-2020', 'vlan-2025', 'vlan-2024']}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aci_bd_subnet': {'gateway': ['10.1.10.1',\n",
       "   '10.1.13.1',\n",
       "   '10.1.11.1',\n",
       "   '10.1.12.1']},\n",
       " 'aci_bd': {'gateway': ['10.1.10.1', '10.1.13.1', '10.1.11.1']},\n",
       " 'aci_epg_to_domain': {'primary_encap': ['vlan-2027',\n",
       "   'vlan-2023',\n",
       "   'vlan-2026',\n",
       "   'vlan-2022',\n",
       "   'vlan-2021',\n",
       "   'vlan-2020',\n",
       "   'vlan-2025',\n",
       "   'vlan-2024']},\n",
       " 'aci_epg': {'primary_encap': ['vlan-2027',\n",
       "   'vlan-2023',\n",
       "   'vlan-2026',\n",
       "   'vlan-2022',\n",
       "   'vlan-2021',\n",
       "   'vlan-2020']}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_siblings(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aci_tenant': {'children': [{'aci_vrf': {'vrf': 'dev.dev-vrf',\n",
       "     'state': 'present'}},\n",
       "   {'aci_bd': {'children': [{'aci_bd_subnet': {'mask': 24,\n",
       "        'gateway': '10.1.10.1',\n",
       "        'state': 'present'}},\n",
       "      {'fvRsCtx': {'tnFvCtxName': 'dev.dev-vrf', 'state': 'present'}}],\n",
       "     'endpoint_retention_action': 'resolve',\n",
       "     'vrf': 'dev.dev-vrf',\n",
       "     'arp_flooding': 'yes',\n",
       "     'enable_rogue_except_mac': 'no',\n",
       "     'mac_address': '00:22:BD:F8:19:FF',\n",
       "     'bd': '10.1.10.0_24',\n",
       "     'l2_unknown_unicast': 'flood',\n",
       "     'state': 'present'}},\n",
       "   {'aci_bd': {'children': [{'aci_bd_subnet': {'mask': 24,\n",
       "        'gateway': '10.1.13.1',\n",
       "        'state': 'present'}},\n",
       "      {'fvRsCtx': {'tnFvCtxName': 'dev.dev-vrf', 'state': 'present'}}],\n",
       "     'endpoint_retention_action': 'resolve',\n",
       "     'vrf': 'dev.dev-vrf',\n",
       "     'arp_flooding': 'yes',\n",
       "     'enable_rogue_except_mac': 'no',\n",
       "     'mac_address': '00:22:BD:F8:19:FF',\n",
       "     'bd': '10.1.13.0_24',\n",
       "     'l2_unknown_unicast': 'flood',\n",
       "     'state': 'present'}},\n",
       "   {'aci_bd': {'children': [{'aci_bd_subnet': {'mask': 24,\n",
       "        'gateway': '10.1.11.1',\n",
       "        'state': 'present'}},\n",
       "      {'fvRsCtx': {'tnFvCtxName': 'dev.dev-vrf', 'state': 'present'}}],\n",
       "     'endpoint_retention_action': 'resolve',\n",
       "     'vrf': 'dev.dev-vrf',\n",
       "     'arp_flooding': 'yes',\n",
       "     'enable_rogue_except_mac': 'no',\n",
       "     'mac_address': '00:22:BD:F8:19:FF',\n",
       "     'bd': '10.1.11.0_24',\n",
       "     'l2_unknown_unicast': 'flood',\n",
       "     'state': 'present'}},\n",
       "   {'aci_bd': {'children': [{'aci_bd_subnet': {'mask': 24,\n",
       "        'gateway': '10.1.12.1',\n",
       "        'state': 'present'}},\n",
       "      {'fvRsCtx': {'tnFvCtxName': 'dev.dev-vrf', 'state': 'present'}}],\n",
       "     'endpoint_retention_action': 'resolve',\n",
       "     'vrf': 'dev.dev-vrf',\n",
       "     'arp_flooding': 'yes',\n",
       "     'enable_rogue_except_mac': 'no',\n",
       "     'mac_address': '00:22:BD:F8:19:FF',\n",
       "     'bd': '10.1.12.0_24',\n",
       "     'l2_unknown_unicast': 'flood',\n",
       "     'state': 'present'}},\n",
       "   {},\n",
       "   {'aci_ap': {'children': [{'aci_esg': {'children': [{'fvRsScope': {'tnFvCtxName': 'dev.dev-vrf',\n",
       "           'state': 'present'}},\n",
       "         {'aci_epg_to_contract_interface': {'tnVzCPIfName': 'to_common_l3out_to_core_ospf',\n",
       "           'state': 'present'}},\n",
       "         {'fvEPgSelector': {'matchEpgDn': 'uni/tn-dev/ap-network-segments/epg-10.1.11.0_24',\n",
       "           'state': 'present'}},\n",
       "         {'fvEPgSelector': {'matchEpgDn': 'uni/tn-dev/ap-network-segments/epg-10.1.10.0_24',\n",
       "           'state': 'present'}},\n",
       "         {'fvEPgSelector': {'matchEpgDn': 'uni/tn-dev/ap-network-segments/epg-10.1.12.0_24',\n",
       "           'state': 'present'}},\n",
       "         {'fvEPgSelector': {'matchEpgDn': 'uni/tn-dev/ap-network-segments/epg-10.1.13.0_24',\n",
       "           'state': 'present'}}],\n",
       "        'description': 'ESG used to group all endpoints from EPGs',\n",
       "        'esg': 'all-services',\n",
       "        'state': 'present'}},\n",
       "      {'aci_epg': {'children': [{'aci_epg_to_domain': {'allow_useg': 'useg',\n",
       "           'encap': 'vlan-2027',\n",
       "           'deploy_immediacy': 'immediate',\n",
       "           'number_of_ports': '0',\n",
       "           'primary_encap': 'vlan-2026',\n",
       "           'primaryEncapInner': 'unknown',\n",
       "           'resolution_immediacy': 'immediate',\n",
       "           'secondaryEncapInner': 'unknown',\n",
       "           'state': 'present'}},\n",
       "         {'fvRsBd': {'tnFvBDName': '10.1.13.0_24', 'state': 'present'}}],\n",
       "        'epg': '10.1.13.0_24',\n",
       "        'state': 'present'}},\n",
       "      {'aci_epg': {'children': [{'aci_epg_to_domain': {'allow_useg': 'useg',\n",
       "           'encap': 'vlan-2023',\n",
       "           'deploy_immediacy': 'immediate',\n",
       "           'number_of_ports': '0',\n",
       "           'primary_encap': 'vlan-2022',\n",
       "           'primaryEncapInner': 'unknown',\n",
       "           'resolution_immediacy': 'immediate',\n",
       "           'secondaryEncapInner': 'unknown',\n",
       "           'state': 'present'}},\n",
       "         {'fvRsBd': {'tnFvBDName': '10.1.11.0_24', 'state': 'present'}}],\n",
       "        'epg': '10.1.11.0_24',\n",
       "        'state': 'present'}},\n",
       "      {'aci_epg': {'children': [{'aci_epg_to_domain': {'allow_useg': 'useg',\n",
       "           'encap': 'vlan-2021',\n",
       "           'deploy_immediacy': 'immediate',\n",
       "           'number_of_ports': '0',\n",
       "           'primary_encap': 'vlan-2020',\n",
       "           'primaryEncapInner': 'unknown',\n",
       "           'resolution_immediacy': 'immediate',\n",
       "           'secondaryEncapInner': 'unknown',\n",
       "           'state': 'present'}},\n",
       "         {'fvRsBd': {'tnFvBDName': '10.1.10.0_24', 'state': 'present'}}],\n",
       "        'epg': '10.1.10.0_24',\n",
       "        'state': 'present'}},\n",
       "      {'aci_epg': {'children': [{'aci_epg_to_domain': {'allow_useg': 'useg',\n",
       "           'encap': 'vlan-2025',\n",
       "           'deploy_immediacy': 'immediate',\n",
       "           'number_of_ports': '0',\n",
       "           'primary_encap': 'vlan-2024',\n",
       "           'primaryEncapInner': 'unknown',\n",
       "           'resolution_immediacy': 'immediate',\n",
       "           'secondaryEncapInner': 'unknown',\n",
       "           'state': 'present'}},\n",
       "         {'fvRsBd': {'tnFvBDName': '10.1.12.0_24', 'state': 'present'}}],\n",
       "        'epg': '10.1.12.0_24',\n",
       "        'state': 'present'}}],\n",
       "     'ap': 'network-segments',\n",
       "     'state': 'present'}}],\n",
       "  'tenant': 'dev_mart',\n",
       "  'state': 'present'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_attributes(data, \n",
    "                          parent_key=None, \n",
    "                          grandparent_key=None, \n",
    "                          great_grandparent_key=None, \n",
    "                          great_great_grandparent_key=None, \n",
    "                          parent_name=None, \n",
    "                          grandparent_name=None, \n",
    "                          great_grandparent_name=None, \n",
    "                          great_great_grandparent_name=None, \n",
    "                          changes=None):\n",
    "\n",
    "    if changes is None:\n",
    "        changes = {}\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            try:\n",
    "                current_name = reverseAliases[key][\"name\"][:-1]  # remove mandatory tag\n",
    "            except KeyError:\n",
    "                current_name = None\n",
    "\n",
    "            if parent_key == \"children\": # need to append all this info for later use - iterate over pairwise, will work just fine\n",
    "                change = [i for i in [parent_name, grandparent_name, great_grandparent_name, great_great_grandparent_name, grandparent_key, great_great_grandparent_key] if i is not None]\n",
    "                changes[key] = change\n",
    "\n",
    "            # could make it more clear somehow.. \n",
    "            get_parent_attributes(value, key, parent_key, grandparent_key, great_grandparent_key, \n",
    "                                  current_name, parent_name, grandparent_name, great_grandparent_name, changes)\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            get_parent_attributes(item, parent_key, grandparent_key, great_grandparent_key, great_great_grandparent_key, \n",
    "                                  parent_name, grandparent_name, great_grandparent_name, great_great_grandparent_name, changes)\n",
    "\n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappp = get_parent_attributes(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aci_vrf': ['tenant', 'aci_tenant'],\n",
       " 'aci_bd': ['tenant', 'aci_tenant'],\n",
       " 'aci_bd_subnet': ['bd', 'tenant', 'aci_bd', 'aci_tenant'],\n",
       " 'fvRsCtx': ['bd', 'tenant', 'aci_bd', 'aci_tenant'],\n",
       " 'aci_ap': ['tenant', 'aci_tenant'],\n",
       " 'aci_esg': ['ap', 'tenant', 'aci_ap', 'aci_tenant'],\n",
       " 'fvRsScope': ['esg', 'ap', 'aci_esg', 'aci_ap'],\n",
       " 'aci_epg_to_contract_interface': ['esg', 'ap', 'aci_esg', 'aci_ap'],\n",
       " 'fvEPgSelector': ['esg', 'ap', 'aci_esg', 'aci_ap'],\n",
       " 'aci_epg': ['ap', 'tenant', 'aci_ap', 'aci_tenant'],\n",
       " 'aci_epg_to_domain': ['epg', 'ap', 'aci_epg', 'aci_ap'],\n",
       " 'fvRsBd': ['epg', 'ap', 'aci_epg', 'aci_ap']}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_yml(data, dn_attributes_map = mappp, credentials_file = None, yml_list = [], parent_key = None, grandparent_key = None):\n",
    "\n",
    "        entry_dict = {}\n",
    "\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "\n",
    "                nested_dictionary = {}\n",
    "\n",
    "                # here restructuring is handled\n",
    "                if parent_key == \"children\" or parent_key == None:\n",
    "\n",
    "                    # bad trick to get rid of all non-aci modules\n",
    "                    if key[:3] == \"aci\":\n",
    "                        pass\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                    # set name to something generic\n",
    "                    key_name = key.split(\"_\")[1] if len(key.split(\"_\")) == 2 else key.split(\"_\")[2]\n",
    "\n",
    "                    if parent_key != None:\n",
    "                        grandparent_key_name = grandparent_key.split(\"_\")[1] if len(grandparent_key.split(\"_\")) == 2 else grandparent_key.split(\"_\")[2:]\n",
    "                        sentence = f\"add a {key_name.upper()} to the {grandparent_key_name.upper()}\"\n",
    "                    else:\n",
    "                        sentence = f\"create {key_name} on ACI using {key} module\"\n",
    "\n",
    "                    entry_dict[\"name\"] = sentence\n",
    "                    for subkey, subvalue in data[key].items():\n",
    "                        if subkey != \"children\":\n",
    "                            # print(key, subkey, subvalue)\n",
    "                            nested_dictionary[subkey] = subvalue\n",
    "\n",
    "\n",
    "                    if key in dn_attributes_map:\n",
    "                        print(dn_attributes_map[key])\n",
    "\n",
    "\n",
    "                    \n",
    "                    entry_dict[\"cisco.aci.\" + key] = nested_dictionary\n",
    "                    entry_dict[\"delegate_to\"] = \"localhost\"\n",
    "\n",
    "                    yml_list.append(entry_dict)\n",
    "\n",
    "                if isinstance(value, dict):\n",
    "                    rebuild_yml(value, parent_key = key, grandparent_key = parent_key)\n",
    "\n",
    "                elif isinstance(value, list):\n",
    "                    for item in value:\n",
    "                        rebuild_yml(item, parent_key = key, grandparent_key = parent_key)\n",
    "\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                rebuild_yml(item, parent_key = key, grandparent_key = parent_key)\n",
    "\n",
    "        return yml_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tenant', 'aci_tenant']\n",
      "['tenant', 'aci_tenant']\n",
      "['bd', 'tenant', 'aci_bd', 'aci_tenant']\n",
      "['tenant', 'aci_tenant']\n",
      "['bd', 'tenant', 'aci_bd', 'aci_tenant']\n",
      "['tenant', 'aci_tenant']\n",
      "['bd', 'tenant', 'aci_bd', 'aci_tenant']\n",
      "['tenant', 'aci_tenant']\n",
      "['bd', 'tenant', 'aci_bd', 'aci_tenant']\n",
      "['tenant', 'aci_tenant']\n",
      "['ap', 'tenant', 'aci_ap', 'aci_tenant']\n",
      "['esg', 'ap', 'aci_esg', 'aci_ap']\n",
      "['ap', 'tenant', 'aci_ap', 'aci_tenant']\n",
      "['epg', 'ap', 'aci_epg', 'aci_ap']\n",
      "['ap', 'tenant', 'aci_ap', 'aci_tenant']\n",
      "['epg', 'ap', 'aci_epg', 'aci_ap']\n",
      "['ap', 'tenant', 'aci_ap', 'aci_tenant']\n",
      "['epg', 'ap', 'aci_epg', 'aci_ap']\n",
      "['ap', 'tenant', 'aci_ap', 'aci_tenant']\n",
      "['epg', 'ap', 'aci_epg', 'aci_ap']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'create tenant on ACI using aci_tenant module',\n",
       "  'cisco.aci.aci_tenant': {'tenant': 'dev_mart', 'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a VRF to the TENANT',\n",
       "  'cisco.aci.aci_vrf': {'vrf': 'dev.dev-vrf', 'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a BD to the TENANT',\n",
       "  'cisco.aci.aci_bd': {'endpoint_retention_action': 'resolve',\n",
       "   'vrf': 'dev.dev-vrf',\n",
       "   'arp_flooding': 'yes',\n",
       "   'enable_rogue_except_mac': 'no',\n",
       "   'mac_address': '00:22:BD:F8:19:FF',\n",
       "   'bd': '10.1.10.0_24',\n",
       "   'l2_unknown_unicast': 'flood',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a SUBNET to the BD',\n",
       "  'cisco.aci.aci_bd_subnet': {'mask': 24,\n",
       "   'gateway': '10.1.10.1',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a BD to the TENANT',\n",
       "  'cisco.aci.aci_bd': {'endpoint_retention_action': 'resolve',\n",
       "   'vrf': 'dev.dev-vrf',\n",
       "   'arp_flooding': 'yes',\n",
       "   'enable_rogue_except_mac': 'no',\n",
       "   'mac_address': '00:22:BD:F8:19:FF',\n",
       "   'bd': '10.1.13.0_24',\n",
       "   'l2_unknown_unicast': 'flood',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a SUBNET to the BD',\n",
       "  'cisco.aci.aci_bd_subnet': {'mask': 24,\n",
       "   'gateway': '10.1.13.1',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a BD to the TENANT',\n",
       "  'cisco.aci.aci_bd': {'endpoint_retention_action': 'resolve',\n",
       "   'vrf': 'dev.dev-vrf',\n",
       "   'arp_flooding': 'yes',\n",
       "   'enable_rogue_except_mac': 'no',\n",
       "   'mac_address': '00:22:BD:F8:19:FF',\n",
       "   'bd': '10.1.11.0_24',\n",
       "   'l2_unknown_unicast': 'flood',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a SUBNET to the BD',\n",
       "  'cisco.aci.aci_bd_subnet': {'mask': 24,\n",
       "   'gateway': '10.1.11.1',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a BD to the TENANT',\n",
       "  'cisco.aci.aci_bd': {'endpoint_retention_action': 'resolve',\n",
       "   'vrf': 'dev.dev-vrf',\n",
       "   'arp_flooding': 'yes',\n",
       "   'enable_rogue_except_mac': 'no',\n",
       "   'mac_address': '00:22:BD:F8:19:FF',\n",
       "   'bd': '10.1.12.0_24',\n",
       "   'l2_unknown_unicast': 'flood',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a SUBNET to the BD',\n",
       "  'cisco.aci.aci_bd_subnet': {'mask': 24,\n",
       "   'gateway': '10.1.12.1',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a AP to the TENANT',\n",
       "  'cisco.aci.aci_ap': {'ap': 'network-segments', 'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a ESG to the AP',\n",
       "  'cisco.aci.aci_esg': {'description': 'ESG used to group all endpoints from EPGs',\n",
       "   'esg': 'all-services',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a TO to the ESG',\n",
       "  'cisco.aci.aci_epg_to_contract_interface': {'tnVzCPIfName': 'to_common_l3out_to_core_ospf',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a EPG to the AP',\n",
       "  'cisco.aci.aci_epg': {'epg': '10.1.13.0_24', 'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a TO to the EPG',\n",
       "  'cisco.aci.aci_epg_to_domain': {'allow_useg': 'useg',\n",
       "   'encap': 'vlan-2027',\n",
       "   'deploy_immediacy': 'immediate',\n",
       "   'number_of_ports': '0',\n",
       "   'primary_encap': 'vlan-2026',\n",
       "   'primaryEncapInner': 'unknown',\n",
       "   'resolution_immediacy': 'immediate',\n",
       "   'secondaryEncapInner': 'unknown',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a EPG to the AP',\n",
       "  'cisco.aci.aci_epg': {'epg': '10.1.11.0_24', 'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a TO to the EPG',\n",
       "  'cisco.aci.aci_epg_to_domain': {'allow_useg': 'useg',\n",
       "   'encap': 'vlan-2023',\n",
       "   'deploy_immediacy': 'immediate',\n",
       "   'number_of_ports': '0',\n",
       "   'primary_encap': 'vlan-2022',\n",
       "   'primaryEncapInner': 'unknown',\n",
       "   'resolution_immediacy': 'immediate',\n",
       "   'secondaryEncapInner': 'unknown',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a EPG to the AP',\n",
       "  'cisco.aci.aci_epg': {'epg': '10.1.10.0_24', 'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a TO to the EPG',\n",
       "  'cisco.aci.aci_epg_to_domain': {'allow_useg': 'useg',\n",
       "   'encap': 'vlan-2021',\n",
       "   'deploy_immediacy': 'immediate',\n",
       "   'number_of_ports': '0',\n",
       "   'primary_encap': 'vlan-2020',\n",
       "   'primaryEncapInner': 'unknown',\n",
       "   'resolution_immediacy': 'immediate',\n",
       "   'secondaryEncapInner': 'unknown',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a EPG to the AP',\n",
       "  'cisco.aci.aci_epg': {'epg': '10.1.12.0_24', 'state': 'present'},\n",
       "  'delegate_to': 'localhost'},\n",
       " {'name': 'add a TO to the EPG',\n",
       "  'cisco.aci.aci_epg_to_domain': {'allow_useg': 'useg',\n",
       "   'encap': 'vlan-2025',\n",
       "   'deploy_immediacy': 'immediate',\n",
       "   'number_of_ports': '0',\n",
       "   'primary_encap': 'vlan-2024',\n",
       "   'primaryEncapInner': 'unknown',\n",
       "   'resolution_immediacy': 'immediate',\n",
       "   'secondaryEncapInner': 'unknown',\n",
       "   'state': 'present'},\n",
       "  'delegate_to': 'localhost'}]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuild_yml(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cisco.aci.aci_tenant\n",
      "cisco.aci.aci_vrf\n",
      "cisco.aci.aci_bd\n",
      "cisco.aci.aci_bd_subnet\n",
      "cisco.aci.aci_bd\n",
      "cisco.aci.aci_bd_subnet\n",
      "cisco.aci.aci_bd\n",
      "cisco.aci.aci_bd_subnet\n",
      "cisco.aci.aci_bd\n",
      "cisco.aci.aci_bd_subnet\n",
      "cisco.aci.aci_ap\n",
      "cisco.aci.aci_esg\n",
      "cisco.aci.aci_epg_to_contract_interface\n",
      "cisco.aci.aci_epg\n",
      "cisco.aci.aci_epg_to_domain\n",
      "cisco.aci.aci_epg\n",
      "cisco.aci.aci_epg_to_domain\n",
      "cisco.aci.aci_epg\n",
      "cisco.aci.aci_epg_to_domain\n",
      "cisco.aci.aci_epg\n",
      "cisco.aci.aci_epg_to_domain\n",
      "cisco.aci.aci_tenant\n",
      "cisco.aci.aci_vrf\n",
      "cisco.aci.aci_bd\n",
      "cisco.aci.aci_bd_subnet\n",
      "cisco.aci.aci_bd\n",
      "cisco.aci.aci_bd_subnet\n",
      "cisco.aci.aci_bd\n",
      "cisco.aci.aci_bd_subnet\n",
      "cisco.aci.aci_bd\n",
      "cisco.aci.aci_bd_subnet\n",
      "cisco.aci.aci_ap\n",
      "cisco.aci.aci_esg\n",
      "cisco.aci.aci_epg_to_contract_interface\n",
      "cisco.aci.aci_epg\n",
      "cisco.aci.aci_epg_to_domain\n",
      "cisco.aci.aci_epg\n",
      "cisco.aci.aci_epg_to_domain\n",
      "cisco.aci.aci_epg\n",
      "cisco.aci.aci_epg_to_domain\n",
      "cisco.aci.aci_epg\n",
      "cisco.aci.aci_epg_to_domain\n"
     ]
    }
   ],
   "source": [
    "for module in spe:\n",
    "    for key, value in module.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
